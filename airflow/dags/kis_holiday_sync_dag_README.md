# KIS Holiday Sync DAG - KIS êµ­ë‚´íœ´ì¥ì¼ ë™ê¸°í™” ì›Œí¬í”Œë¡œìš°

## ê°œìš”

**KIS Holiday Sync DAG**ëŠ” KIS APIì˜ êµ­ë‚´íœ´ì¥ì¼ì¡°íšŒ(TCA0903R) ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í•œêµ­ ì£¼ì‹ì‹œì¥ì˜ íœ´ì¥ì¼ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” Airflow DAGì…ë‹ˆë‹¤.

- **DAG ID**: `kis_holiday_sync`
- **ì‹¤í–‰ ì£¼ê¸°**: ë§¤ì¼ ì˜¤ì „ 6ì‹œ (ì¥ ì‹œì‘ ì „)
- **API ì œí•œ**: 1ì¼ 1íšŒ í˜¸ì¶œ ì œí•œ ì¤€ìˆ˜
- **ì¬ì‹œë„**: 3íšŒ, 30ë¶„ ê°„ê²©

## ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°

```
fetch_holiday_data â†’ store_holiday_data â†’ validate_holiday_data
```

## ìƒì„¸ ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤

### STEP 1: íœ´ì¥ì¼ ë°ì´í„° ì¡°íšŒ (fetch_holiday_data)
**íƒœìŠ¤í¬ ID**: `fetch_holiday_data`
**ê¸°ëŠ¥**: KIS APIì—ì„œ íœ´ì¥ì¼ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ê²€ì¦

#### 1.1 KIS API ì¸ì¦ ë° í˜¸ì¶œ
```python
@task(retries=3, retry_delay=timedelta(minutes=30))
def fetch_holiday_data() -> Dict[str, Any]:
    """
    KIS APIì—ì„œ íœ´ì¥ì¼ ë°ì´í„° ì¡°íšŒ
    1ì¼ 1íšŒ ì œí•œ ì¤€ìˆ˜
    """
    logging.info("KIS íœ´ì¥ì¼ ë°ì´í„° ì¡°íšŒ ì‹œì‘")
    
    # FastAPI ì„œë²„ë¥¼ í†µí•œ KIS API í˜¸ì¶œ
    base_url = "http://localhost:8000"
    endpoint = "/domestic/holiday"
    
    try:
        response = requests.get(f"{base_url}{endpoint}", timeout=30)
        response.raise_for_status()
        
        holiday_data = response.json()
        logging.info(f"âœ… íœ´ì¥ì¼ ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ: {len(holiday_data.get('output', []))}ê±´")
        
        return {
            'status': 'success',
            'data': holiday_data,
            'count': len(holiday_data.get('output', [])),
            'api_response_time': response.elapsed.total_seconds()
        }
        
    except requests.exceptions.RequestException as e:
        logging.error(f"âŒ KIS API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise
    except Exception as e:
        logging.error(f"âŒ íœ´ì¥ì¼ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise
```

#### 1.2 API ì‘ë‹µ ë°ì´í„° êµ¬ì¡° ê²€ì¦
```python
def validate_api_response(holiday_data: Dict[str, Any]) -> bool:
    """API ì‘ë‹µ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš© ê²€ì¦"""
    
    if not holiday_data:
        raise ValueError("íœ´ì¥ì¼ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    # ê¸°ë³¸ ì‘ë‹µ êµ¬ì¡° ê²€ì¦
    required_fields = ['rt_cd', 'msg_cd', 'msg1', 'output']
    for field in required_fields:
        if field not in holiday_data:
            raise ValueError(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
    
    # ì„±ê³µ ì‘ë‹µ ì½”ë“œ í™•ì¸
    if holiday_data.get('rt_cd') != '0':
        error_msg = holiday_data.get('msg1', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
        raise ValueError(f"API ì˜¤ë¥˜ ì‘ë‹µ: {error_msg}")
    
    # íœ´ì¥ì¼ ë°ì´í„° ë°°ì—´ ê²€ì¦
    holidays = holiday_data.get('output', [])
    if not isinstance(holidays, list):
        raise ValueError("íœ´ì¥ì¼ ë°ì´í„°ê°€ ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")
    
    logging.info(f"ğŸ“… íœ´ì¥ì¼ ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {len(holidays)}ê±´")
    return True
```

#### 1.3 íœ´ì¥ì¼ ë°ì´í„° íŒŒì‹± ë° ì •ê·œí™”
```python
def parse_holiday_data(raw_holidays: List[Dict]) -> List[Dict[str, Any]]:
    """íœ´ì¥ì¼ ë°ì´í„°ë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    parsed_holidays = []
    
    for holiday in raw_holidays:
        try:
            # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
            holiday_date = holiday.get('bzdy_dd')  # ì˜ì—…ì¼ì (YYYYMMDD)
            holiday_name = holiday.get('bzdy_nm', '').strip()  # íœ´ì¥ì¼ëª…
            
            if not holiday_date or len(holiday_date) != 8:
                logging.warning(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ìŠ¤í‚µ: {holiday_date}")
                continue
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ ë° ê²€ì¦
            try:
                parsed_date = datetime.strptime(holiday_date, '%Y%m%d').date()
            except ValueError:
                logging.warning(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ìŠ¤í‚µ: {holiday_date}")
                continue
            
            # ì •ê·œí™”ëœ íœ´ì¥ì¼ ë°ì´í„°
            parsed_holidays.append({
                'holiday_date': parsed_date,
                'holiday_name': holiday_name or 'íœ´ì¥ì¼',
                'market_type': 'DOMESTIC',  # êµ­ë‚´ì‹œì¥
                'is_active': True,
                'raw_data': holiday,  # ì›ë³¸ ë°ì´í„° ë³´ì¡´
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            })
            
        except Exception as e:
            logging.error(f"âŒ íœ´ì¥ì¼ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {holiday} - {e}")
            continue
    
    logging.info(f"ğŸ”§ íœ´ì¥ì¼ ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(parsed_holidays)}ê±´")
    return parsed_holidays
```

### STEP 2: íœ´ì¥ì¼ ë°ì´í„° ì €ì¥ (store_holiday_data)
**íƒœìŠ¤í¬ ID**: `store_holiday_data`
**ê¸°ëŠ¥**: íŒŒì‹±ëœ íœ´ì¥ì¼ ë°ì´í„°ë¥¼ PostgreSQLì— UPSERT

#### 2.1 ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° í…Œì´ë¸” ì¤€ë¹„
```python
@task(retries=2, retry_delay=timedelta(minutes=5))
def store_holiday_data(holiday_fetch_result: Dict[str, Any]) -> Dict[str, Any]:
    """íœ´ì¥ì¼ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥"""
    
    if holiday_fetch_result['status'] != 'success':
        raise ValueError("íœ´ì¥ì¼ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ë¡œ ì €ì¥ ë¶ˆê°€")
    
    # PostgreSQL ì—°ê²°
    connection = psycopg2.connect(
        host="localhost",
        port=5433,
        database="quantum_trading",
        user="quantum",
        password="quantum123"
    )
    
    try:
        cursor = connection.cursor(cursor_factory=RealDictCursor)
        
        # íœ´ì¥ì¼ ë°ì´í„° íŒŒì‹±
        raw_holidays = holiday_fetch_result['data'].get('output', [])
        parsed_holidays = parse_holiday_data(raw_holidays)
        
        if not parsed_holidays:
            logging.warning("âš ï¸ ì €ì¥í•  íœ´ì¥ì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {'stored_count': 0, 'updated_count': 0}
```

#### 2.2 UPSERT ì¿¼ë¦¬ ì‹¤í–‰
```python
        # UPSERT ì¿¼ë¦¬ (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)
        upsert_query = """
        INSERT INTO kis_domestic_holidays 
        (holiday_date, holiday_name, market_type, is_active, raw_data, created_at, updated_at)
        VALUES (%(holiday_date)s, %(holiday_name)s, %(market_type)s, 
                %(is_active)s, %(raw_data)s, %(created_at)s, %(updated_at)s)
        ON CONFLICT (holiday_date) DO UPDATE SET
            holiday_name = EXCLUDED.holiday_name,
            is_active = EXCLUDED.is_active,
            raw_data = EXCLUDED.raw_data,
            updated_at = EXCLUDED.updated_at
        """
        
        stored_count = 0
        updated_count = 0
        
        for holiday in parsed_holidays:
            try:
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                cursor.execute(
                    "SELECT id FROM kis_domestic_holidays WHERE holiday_date = %s",
                    (holiday['holiday_date'],)
                )
                existing = cursor.fetchone()
                
                # UPSERT ì‹¤í–‰
                cursor.execute(upsert_query, {
                    'holiday_date': holiday['holiday_date'],
                    'holiday_name': holiday['holiday_name'],
                    'market_type': holiday['market_type'],
                    'is_active': holiday['is_active'],
                    'raw_data': json.dumps(holiday['raw_data']),
                    'created_at': holiday['created_at'],
                    'updated_at': holiday['updated_at']
                })
                
                if existing:
                    updated_count += 1
                else:
                    stored_count += 1
                    
            except Exception as e:
                logging.error(f"âŒ íœ´ì¥ì¼ ì €ì¥ ì‹¤íŒ¨: {holiday['holiday_date']} - {e}")
                continue
        
        # íŠ¸ëœì­ì…˜ ì»¤ë°‹
        connection.commit()
        
        logging.info(f"ğŸ’¾ íœ´ì¥ì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
        logging.info(f"   - ì‹ ê·œ ì €ì¥: {stored_count}ê±´")
        logging.info(f"   - ì—…ë°ì´íŠ¸: {updated_count}ê±´")
        
        return {
            'stored_count': stored_count,
            'updated_count': updated_count,
            'total_processed': len(parsed_holidays)
        }
        
    finally:
        cursor.close()
        connection.close()
```

### STEP 3: íœ´ì¥ì¼ ë°ì´í„° ê²€ì¦ (validate_holiday_data)
**íƒœìŠ¤í¬ ID**: `validate_holiday_data`
**ê¸°ëŠ¥**: ì €ì¥ëœ íœ´ì¥ì¼ ë°ì´í„°ì˜ ë¬´ê²°ì„± ë° ì™„ì „ì„± ê²€ì¦

#### 3.1 ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
```python
@task
def validate_holiday_data(store_result: Dict[str, Any]) -> Dict[str, str]:
    """ì €ì¥ëœ íœ´ì¥ì¼ ë°ì´í„° ê²€ì¦"""
    
    connection = psycopg2.connect(
        host="localhost",
        port=5433,
        database="quantum_trading",
        user="quantum",
        password="quantum123"
    )
    
    try:
        cursor = connection.cursor(cursor_factory=RealDictCursor)
        
        # 1. ê¸°ë³¸ í†µê³„ ì¡°íšŒ
        cursor.execute("""
            SELECT 
                COUNT(*) as total_count,
                COUNT(CASE WHEN is_active = TRUE THEN 1 END) as active_count,
                MIN(holiday_date) as earliest_date,
                MAX(holiday_date) as latest_date
            FROM kis_domestic_holidays
        """)
        
        stats = cursor.fetchone()
        
        logging.info(f"ğŸ“Š íœ´ì¥ì¼ ë°ì´í„° í†µê³„:")
        logging.info(f"   - ì „ì²´ ê±´ìˆ˜: {stats['total_count']}")
        logging.info(f"   - í™œì„± ê±´ìˆ˜: {stats['active_count']}")
        logging.info(f"   - ë‚ ì§œ ë²”ìœ„: {stats['earliest_date']} ~ {stats['latest_date']}")
```

#### 3.2 ë°ì´í„° í’ˆì§ˆ ê²€ì¦
```python
        # 2. ì¤‘ë³µ ë°ì´í„° ê²€ì¦
        cursor.execute("""
            SELECT holiday_date, COUNT(*) as cnt 
            FROM kis_domestic_holidays 
            GROUP BY holiday_date 
            HAVING COUNT(*) > 1
        """)
        
        duplicates = cursor.fetchall()
        if duplicates:
            logging.warning(f"âš ï¸ ì¤‘ë³µëœ íœ´ì¥ì¼ ë°œê²¬: {len(duplicates)}ê±´")
            for dup in duplicates:
                logging.warning(f"   - {dup['holiday_date']}: {dup['cnt']}ê±´")
        
        # 3. ìµœê·¼ ì—…ë°ì´íŠ¸ ë°ì´í„° í™•ì¸
        cursor.execute("""
            SELECT COUNT(*) as recent_count
            FROM kis_domestic_holidays 
            WHERE updated_at >= NOW() - INTERVAL '1 DAY'
        """)
        
        recent_updates = cursor.fetchone()['recent_count']
        
        # 4. í–¥í›„ 1ë…„ íœ´ì¥ì¼ í™•ì¸
        cursor.execute("""
            SELECT COUNT(*) as future_holidays
            FROM kis_domestic_holidays 
            WHERE holiday_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '1 YEAR'
            AND is_active = TRUE
        """)
        
        future_count = cursor.fetchone()['future_holidays']
        
        logging.info(f"âœ… íœ´ì¥ì¼ ë°ì´í„° ê²€ì¦ ì™„ë£Œ:")
        logging.info(f"   - ìµœê·¼ ì—…ë°ì´íŠ¸: {recent_updates}ê±´")
        logging.info(f"   - í–¥í›„ 1ë…„ íœ´ì¥ì¼: {future_count}ê±´")
        logging.info(f"   - ì¤‘ë³µ ë°ì´í„°: {len(duplicates)}ê±´")
        
        # ê²€ì¦ ê²°ê³¼ ë°˜í™˜
        validation_status = "SUCCESS" if len(duplicates) == 0 else "WARNING"
        
        return {
            'status': validation_status,
            'total_count': stats['total_count'],
            'active_count': stats['active_count'],
            'recent_updates': recent_updates,
            'future_holidays': future_count,
            'duplicates': len(duplicates),
            'earliest_date': str(stats['earliest_date']),
            'latest_date': str(stats['latest_date'])
        }
        
    finally:
        cursor.close()
        connection.close()
```

## ë°ì´í„° í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KIS API       â”‚    â”‚  Data Pipeline  â”‚    â”‚  PostgreSQL DB  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚TCA0903R         â”‚â”€â”€â”€â–ºâ”‚1. API í˜¸ì¶œ       â”‚â”€â”€â”€â–ºâ”‚kis_domestic_    â”‚
â”‚(êµ­ë‚´íœ´ì¥ì¼ì¡°íšŒ)  â”‚    â”‚2. ë°ì´í„° ê²€ì¦    â”‚    â”‚holidays í…Œì´ë¸”   â”‚
â”‚1ì¼ 1íšŒ ì œí•œ     â”‚    â”‚3. íŒŒì‹±/ì •ê·œí™”    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚4. UPSERT ì €ì¥   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚5. ë¬´ê²°ì„± ê²€ì¦    â”‚            â–²
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                              â–²                        â”‚
                              â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ 6. í’ˆì§ˆê²€ì¦  â”‚
                       â”‚ ìŠ¤ì¼€ì¤„ëŸ¬     â”‚         â”‚ 7. í†µê³„ìˆ˜ì§‘  â”‚
                       â”‚ ë§¤ì¼ 06:00  â”‚         â”‚ 8. ì•ŒëŒì²´í¬  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### kis_domestic_holidays í…Œì´ë¸” êµ¬ì¡°
```sql
CREATE TABLE kis_domestic_holidays (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    holiday_date DATE NOT NULL UNIQUE,         -- íœ´ì¥ì¼ (YYYY-MM-DD)
    holiday_name VARCHAR(100) NOT NULL,        -- íœ´ì¥ì¼ëª…
    market_type VARCHAR(10) DEFAULT 'DOMESTIC', -- ì‹œì¥êµ¬ë¶„
    is_active BOOLEAN DEFAULT TRUE,            -- í™œì„±ìƒíƒœ
    raw_data JSONB,                           -- ì›ë³¸ API ì‘ë‹µ ë°ì´í„°
    created_at TIMESTAMP DEFAULT NOW(),        -- ìƒì„±ì¼ì‹œ
    updated_at TIMESTAMP DEFAULT NOW()         -- ìˆ˜ì •ì¼ì‹œ
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_kis_holidays_date ON kis_domestic_holidays(holiday_date);
CREATE INDEX idx_kis_holidays_active ON kis_domestic_holidays(is_active);
CREATE INDEX idx_kis_holidays_created ON kis_domestic_holidays(created_at);
```

### ì €ì¥ë˜ëŠ” ë°ì´í„° ì˜ˆì‹œ
```json
{
  "holiday_date": "2025-01-01",
  "holiday_name": "ì‹ ì •",
  "market_type": "DOMESTIC",
  "is_active": true,
  "raw_data": {
    "bzdy_dd": "20250101",
    "bzdy_nm": "ì‹ ì •",
    "wday_dvsn_cd": "7"
  }
}
```

## KIS API ì‘ë‹µ êµ¬ì¡°

### TCA0903R API ì‘ë‹µ ì˜ˆì‹œ
```json
{
  "rt_cd": "0",
  "msg_cd": "MCA00000",
  "msg1": "ì •ìƒì²˜ë¦¬",
  "output": [
    {
      "bzdy_dd": "20250101",        // ì˜ì—…ì¼ì (íœ´ì¥ì¼)
      "bzdy_nm": "ì‹ ì •",            // íœ´ì¥ì¼ëª…
      "wday_dvsn_cd": "7",         // ìš”ì¼êµ¬ë¶„ì½”ë“œ
      "stck_clsg_yn": "Y"          // ì£¼ì‹ì‹œì¥ íœ´ì¥ì—¬ë¶€
    },
    {
      "bzdy_dd": "20250128",
      "bzdy_nm": "ì„¤ë‚  ì—°íœ´",
      "wday_dvsn_cd": "2",
      "stck_clsg_yn": "Y"
    }
  ]
}
```

## ì„±ëŠ¥ ë° ì œì•½ì‚¬í•­

### KIS API ì œì•½ì‚¬í•­
- **í˜¸ì¶œ ì œí•œ**: 1ì¼ 1íšŒë§Œ í˜¸ì¶œ ê°€ëŠ¥
- **ë°ì´í„° ë²”ìœ„**: í–¥í›„ 1ë…„ê°„ì˜ íœ´ì¥ì¼ ì •ë³´
- **ì‘ë‹µ ì‹œê°„**: í‰ê·  1-3ì´ˆ
- **í† í° ë§Œë£Œ**: 6ì‹œê°„ë§ˆë‹¤ ê°±ì‹  í•„ìš”

### ì²˜ë¦¬ ì„±ëŠ¥
- **ë°ì´í„° ì–‘**: ì—°ê°„ ì•½ 60-100ê°œ íœ´ì¥ì¼
- **ì²˜ë¦¬ ì‹œê°„**: í‰ê·  30ì´ˆ ë‚´ì™¸
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: 1MB ì´í•˜
- **ì €ì¥ ìš©ëŸ‰**: íœ´ì¥ì¼ë‹¹ ì•½ 500bytes

### ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„
```python
# ì¬ì‹œë„ ì„¤ì •
default_args = {
    'retries': 3,
    'retry_delay': timedelta(minutes=30)
}

# API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
try:
    response = requests.get(api_url, timeout=30)
except requests.exceptions.Timeout:
    logging.error("â° KIS API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
    raise
except requests.exceptions.ConnectionError:
    logging.error("ğŸŒ KIS API ì—°ê²° ì‹¤íŒ¨")
    raise
```

## ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ

### ì£¼ìš” ë¡œê·¸ ë©”ì‹œì§€
```python
# ì •ìƒ ì²˜ë¦¬
"âœ… íœ´ì¥ì¼ ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ: {count}ê±´"
"ğŸ’¾ íœ´ì¥ì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì‹ ê·œ {new}ê±´, ì—…ë°ì´íŠ¸ {update}ê±´"
"âœ… íœ´ì¥ì¼ ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {total}ê±´"

# ê²½ê³  ìƒí™©
"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ìŠ¤í‚µ: {date}"
"âš ï¸ ì¤‘ë³µëœ íœ´ì¥ì¼ ë°œê²¬: {count}ê±´"
"âš ï¸ ì €ì¥í•  íœ´ì¥ì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"

# ì˜¤ë¥˜ ìƒí™©
"âŒ KIS API í˜¸ì¶œ ì‹¤íŒ¨: {error}"
"âŒ íœ´ì¥ì¼ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {error}"
"âŒ íœ´ì¥ì¼ ì €ì¥ ì‹¤íŒ¨: {date} - {error}"
```

### ì•ŒëŒ ì¡°ê±´
- **API í˜¸ì¶œ ì‹¤íŒ¨**: 3íšŒ ì¬ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ ì•ŒëŒ
- **ë°ì´í„° ì—†ìŒ**: ì‘ë‹µì— íœ´ì¥ì¼ ë°ì´í„°ê°€ ì—†ì„ ë•Œ
- **ì¤‘ë³µ ë°ì´í„°**: ë™ì¼ ë‚ ì§œì˜ ì¤‘ë³µ íœ´ì¥ì¼ ë°œê²¬
- **DB ì—°ê²° ì‹¤íŒ¨**: PostgreSQL ì—°ê²° ë¶ˆê°€

## ì‹¤í–‰ ë° í™•ì¸ ë°©ë²•

### ìˆ˜ë™ ì‹¤í–‰
```bash
# Airflow CLIë¥¼ í†µí•œ ì‹¤í–‰
airflow dags trigger kis_holiday_sync

# íŠ¹ì • ë‚ ì§œë¡œ backfill
airflow dags backfill kis_holiday_sync -s 2025-09-01 -e 2025-09-01
```

### ê²°ê³¼ í™•ì¸ ì¿¼ë¦¬
```sql
-- ìµœê·¼ ì €ì¥ëœ íœ´ì¥ì¼ í™•ì¸
SELECT 
    holiday_date,
    holiday_name,
    created_at,
    updated_at
FROM kis_domestic_holidays 
WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
ORDER BY holiday_date;

-- í–¥í›„ íœ´ì¥ì¼ ëª©ë¡
SELECT 
    holiday_date,
    holiday_name,
    EXTRACT(DOW FROM holiday_date) as day_of_week
FROM kis_domestic_holidays 
WHERE holiday_date >= CURRENT_DATE 
AND is_active = TRUE
ORDER BY holiday_date
LIMIT 10;

-- ì›”ë³„ íœ´ì¥ì¼ í†µê³„
SELECT 
    EXTRACT(YEAR FROM holiday_date) as year,
    EXTRACT(MONTH FROM holiday_date) as month,
    COUNT(*) as holiday_count
FROM kis_domestic_holidays 
WHERE is_active = TRUE
GROUP BY EXTRACT(YEAR FROM holiday_date), EXTRACT(MONTH FROM holiday_date)
ORDER BY year, month;
```

## ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©

### 1. ê±°ë˜ ì‹œìŠ¤í…œ ì—°ë™
```sql
-- ê±°ë˜ ê°€ëŠ¥ì¼ ì²´í¬ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION is_trading_day(check_date DATE)
RETURNS BOOLEAN AS $$
BEGIN
    -- ì£¼ë§ ì²´í¬
    IF EXTRACT(DOW FROM check_date) IN (0, 6) THEN
        RETURN FALSE;
    END IF;
    
    -- íœ´ì¥ì¼ ì²´í¬
    IF EXISTS (
        SELECT 1 FROM kis_domestic_holidays 
        WHERE holiday_date = check_date 
        AND is_active = TRUE
    ) THEN
        RETURN FALSE;
    END IF;
    
    RETURN TRUE;
END;
$$ LANGUAGE plpgsql;
```

### 2. ë‹¤ìŒ ê±°ë˜ì¼ ê³„ì‚°
```sql
-- ë‹¤ìŒ ê±°ë˜ì¼ ì¡°íšŒ
WITH RECURSIVE next_trading_days AS (
    SELECT CURRENT_DATE + 1 as check_date
    
    UNION ALL
    
    SELECT check_date + 1
    FROM next_trading_days
    WHERE NOT is_trading_day(check_date)
    AND check_date < CURRENT_DATE + 30  -- ìµœëŒ€ 30ì¼ í›„ê¹Œì§€
)
SELECT MIN(check_date) as next_trading_day
FROM next_trading_days
WHERE is_trading_day(check_date);
```

### 3. ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§
```python
# íœ´ì¥ì¼ì„ ê³ ë ¤í•œ ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§
def should_run_trading_batch(execution_date):
    """ê±°ë˜ì¼ì—ë§Œ ë°°ì¹˜ ì‘ì—… ì‹¤í–‰"""
    cursor.execute(
        "SELECT is_trading_day(%s)", 
        (execution_date.date(),)
    )
    return cursor.fetchone()[0]

# DAGì—ì„œ ì‚¬ìš©
if not should_run_trading_batch(context['execution_date']):
    return "SKIP"
```

## í™•ì¥ ê³„íš

### ë‹¨ê¸° ê³„íš
- **í•´ì™¸ íœ´ì¥ì¼**: NYSE, NASDAQ íœ´ì¥ì¼ ì¶”ê°€
- **ê³µíœ´ì¼ ì•Œë¦¼**: ë‹¤ê°€ì˜¤ëŠ” íœ´ì¥ì¼ Slack ì•Œë¦¼
- **API ìºì‹±**: ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ ìºì‹± ì‹œìŠ¤í…œ

### ì¥ê¸° ê³„íš
- **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: ì„ì‹œ íœ´ì¥ì¼ ê¸´ê¸‰ ì—…ë°ì´íŠ¸
- **ë‹¤êµ­ê°€ ì§€ì›**: ì•„ì‹œì•„ ì£¼ìš”êµ­ íœ´ì¥ì¼ í†µí•© ê´€ë¦¬
- **ë‹¬ë ¥ ì—°ë™**: Google Calendar, Outlook ì—°ë™

---

**ë¬¸ì„œ ì‘ì„±ì¼**: 2025-09-06  
**ì‘ì„±ì**: Quantum Trading Platform Team  
**ë²„ì „**: 1.0