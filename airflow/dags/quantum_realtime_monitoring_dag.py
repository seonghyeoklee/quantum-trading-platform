"""
Quantum Trading Platform - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ DAG
ì¥ì¤‘ ì‹¤ì‹œê°„ ì£¼ìš” ì¢…ëª© ëª¨ë‹ˆí„°ë§ íŒŒì´í”„ë¼ì¸

Author: Quantum Trading Platform
Created: 2025-09-04
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
# from airflow.operators.http import SimpleHttpOperator  # HTTP operators ë¯¸ì‚¬ìš©
from airflow.operators.dummy import DummyOperator
import logging

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'quantum-trading',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 4),
    'email_on_failure': False,  # ì‹¤ì‹œê°„ì€ ì•Œë¦¼ ë„ê¸°
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
    'execution_timeout': timedelta(minutes=10),
}

# DAG ì •ì˜  
dag = DAG(
    'quantum_realtime_monitoring',
    default_args=default_args,
    description='ì‹¤ì‹œê°„ ì£¼ìš” ì¢…ëª© ëª¨ë‹ˆí„°ë§',
    schedule_interval='*/30 9-15 * * 1-5',  # í‰ì¼ 9ì‹œ-15ì‹œ 30ë¶„ë§ˆë‹¤
    catchup=False,
    tags=['quantum', 'stock', 'realtime', 'monitoring'],
    max_active_runs=1,
)

# ================================================================
# Task Functions
# ================================================================

def check_trading_hours(**context):
    """ê±°ë˜ì‹œê°„ í™•ì¸"""
    from datetime import datetime
    import holidays
    
    execution_date = context['execution_date']
    current_hour = execution_date.hour
    
    # í•œêµ­ ê³µíœ´ì¼ í™•ì¸
    kr_holidays = holidays.SouthKorea()
    is_holiday = execution_date.date() in kr_holidays
    is_weekend = execution_date.weekday() >= 5
    
    # ê±°ë˜ì‹œê°„ í™•ì¸ (9:00-15:30)
    is_trading_hours = 9 <= current_hour <= 15
    
    if is_weekend or is_holiday or not is_trading_hours:
        raise Exception("ê±°ë˜ì‹œê°„ ì™¸ ëª¨ë‹ˆí„°ë§ ìŠ¤í‚µ")
    
    logging.info(f"âœ… ê±°ë˜ì‹œê°„ í™•ì¸: {execution_date}")
    return True

def monitor_key_stocks(**context):
    """ì£¼ìš” ì¢…ëª© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
    import sys
    sys.path.append('/opt/airflow/quantum_analysis')
    
    try:
        # ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (TOP 20)
        key_symbols = [
            "005930", "000660", "035420", "035720", "207940",  # ëŒ€í˜•ì£¼
            "005380", "012330", "000270", "068270", "326030",  # ìë™ì°¨/ë°”ì´ì˜¤
            "AAPL", "MSFT", "GOOGL", "TSLA", "AMZN",           # ë¯¸êµ­ ì£¼ìš”ì£¼
            "NVDA", "META", "JPM", "JNJ", "V"                 # ë¯¸êµ­ ì¶”ê°€
        ]
        
        from core.multi_data_provider import MultiDataProvider
        from datetime import datetime, timedelta
        
        provider = MultiDataProvider(enable_kis=True)
        
        snapshots = []
        for symbol in key_symbols:
            try:
                # ìµœê·¼ 5ì¼ ë°ì´í„°ë¡œ ë¹ ë¥¸ ì²´í¬
                end_date = datetime.now()
                start_date = end_date - timedelta(days=5)
                
                market_data = provider.get_stock_data(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date
                )
                
                if market_data and not market_data.data.empty:
                    latest = market_data.data.iloc[-1]
                    prev = market_data.data.iloc[-2] if len(market_data.data) > 1 else latest
                    
                    snapshot = {
                        'symbol': symbol,
                        'timestamp': datetime.now().isoformat(),
                        'current_price': float(latest['close']),
                        'price_change': float(latest['close'] - prev['close']),
                        'price_change_rate': float((latest['close'] / prev['close'] - 1) * 100),
                        'volume': int(latest['volume']),
                        'data_source': market_data.source.value
                    }
                    snapshots.append(snapshot)
                    
            except Exception as e:
                logging.warning(f"âš ï¸  ì¢…ëª© ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨ {symbol}: {e}")
                continue
        
        logging.info(f"âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ: {len(snapshots)}ê°œ ì¢…ëª©")
        
        # Spring Boot APIë¡œ ì‹¤ì‹œê°„ ë°ì´í„° ì „ì†¡
        return {
            'monitored_stocks': len(snapshots),
            'snapshots': snapshots[:10],  # ìƒìœ„ 10ê°œë§Œ ë¡œê·¸ì—
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        logging.error(f"âŒ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
        raise

def update_realtime_data(**context):
    """ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸"""
    task_instance = context['task_instance']
    monitoring_data = task_instance.xcom_pull(task_ids='monitor_key_stocks')
    
    logging.info(f"ğŸ“Š ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸: {monitoring_data['monitored_stocks']}ê°œ ì¢…ëª©")
    
    # TODO: PostgreSQL realtime_snapshots í…Œì´ë¸”ì— ì €ì¥
    # TODO: WebSocketìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œì— ì‹¤ì‹œê°„ ì „ì†¡
    
    return {"realtime_update": True, "count": monitoring_data['monitored_stocks']}

# ================================================================
# Task Definitions
# ================================================================

# ê±°ë˜ì‹œê°„ í™•ì¸
check_hours = PythonOperator(
    task_id='check_trading_hours',
    python_callable=check_trading_hours,
    dag=dag
)

# ì£¼ìš” ì¢…ëª© ëª¨ë‹ˆí„°ë§
monitor_stocks = PythonOperator(
    task_id='monitor_key_stocks',
    python_callable=monitor_key_stocks,
    dag=dag
)

# ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸
update_data = PythonOperator(
    task_id='update_realtime_data',
    python_callable=update_realtime_data,
    dag=dag
)

# Spring Boot WebSocket ì•Œë¦¼ (ë‚˜ì¤‘ì— êµ¬í˜„)
notify_websocket = DummyOperator(
    task_id='notify_websocket',
    dag=dag
)

# ================================================================
# Task Dependencies  
# ================================================================

check_hours >> monitor_stocks >> update_data >> notify_websocket