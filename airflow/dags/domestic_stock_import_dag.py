"""
êµ­ë‚´ì£¼ì‹ì¢…ëª© ê°€ì ¸ì˜¤ê¸° DAG (DDD ê¸°ë°˜)
- KOSPI/KOSDAQ êµ­ë‚´ ì¢…ëª© íŒŒì¼ íŒŒì‹± ë° DB ì ì¬
- domestic_stocks í…Œì´ë¸” ì‚¬ìš©
- ë°ì´í„° ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬
"""

import os
import re
import uuid
import pandas as pd
import psycopg2
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pytz

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.providers.postgres.operators.postgres import PostgresOperator


# ========================================
# DAG ì„¤ì •
# ========================================
default_args = {
    'owner': 'quantum-trading',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 6, tzinfo=pytz.timezone("Asia/Seoul")),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=10),
    'execution_timeout': timedelta(hours=2),
}

dag = DAG(
    dag_id='Stock_Data__10_Master_Import',
    default_args=default_args,
    description='êµ­ë‚´ì£¼ì‹ì¢…ëª© ê°€ì ¸ì˜¤ê¸° - KOSPI/KOSDAQ ì¢…ëª© íŒŒì¼ íŒŒì‹± ë° DB ì ì¬ (DDD ì„¤ê³„)',
    schedule_interval='0 2 * * 1-5',  # ì£¼ì¤‘ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
    max_active_runs=1,
    catchup=False,
    tags=['domestic-stocks', 'kospi', 'kosdaq', 'ddd'],
)


# ========================================
# íŒŒì¼ íŒŒì‹± í•¨ìˆ˜ë“¤
# ========================================

def parse_domestic_stock_file(file_path: str, market_type: str) -> List[Dict[str, Any]]:
    """
    êµ­ë‚´ ì¢…ëª© íŒŒì¼ íŒŒì‹± (KOSPI/KOSDAQ)
    
    ê³ ì •ê¸¸ì´ í¬ë§·:
    ì¢…ëª©ì½”ë“œ(6) + ì¢…ëª©ëª…(40) + ê¸°íƒ€ì •ë³´...
    """
    results = []
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Stock file not found: {file_path}")
    
    print(f"ğŸ“Š Parsing {market_type} file: {file_path}")
    
    with open(file_path, 'r', encoding='cp949') as f:
        lines = f.readlines()
    
    for line_num, line in enumerate(lines, 1):
        try:
            # ë¼ì¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ (ìµœì†Œ KR7 ìœ„ì¹˜ê¹Œì§€ í™•ì¸)
            if len(line.strip()) < 52:
                continue
            
            # ê³ ì •ê¸¸ì´ íŒŒì‹± (KIS í¬ë§· ê¸°ë°˜)
            # ë¶„ì„ ê²°ê³¼: ì¢…ëª©ì½”ë“œëŠ” 0-6 ìœ„ì¹˜, ì¢…ëª©ëª…ì€ KR7 ì½”ë“œ ë’¤ì— ìœ„ì¹˜
            stock_code = line[0:6].strip()
            
            # KR7 ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
            kr_pos = line.find('KR7')
            if kr_pos > 0:
                # KR7 ì½”ë“œëŠ” 12ìë¦¬ì´ë¯€ë¡œ KR7 + 12 = 15ìë¦¬
                # ê·¸ ë‹¤ìŒë¶€í„° ì¢…ëª©ëª… ì‹œì‘ (ë³´í†µ 21ë²ˆì§¸ ìœ„ì¹˜ë¶€í„°)
                name_start = kr_pos + 12  # KR7 + 9ìë¦¬ = 12
                # ì¢…ëª©ëª…ì€ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ë˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê³µë°±ê¹Œì§€
                name_end = name_start
                while name_end < len(line) and line[name_end] not in [' ', '\t']:
                    name_end += 1
                stock_name = line[name_start:name_end].strip()
            else:
                # KR7ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ìœ„ì¹˜ì—ì„œ ì¶”ì¶œ
                stock_name = line[21:60].strip() if len(line) > 60 else line[21:].strip()
            
            # ìœ íš¨ì„± ê²€ì¦
            if not stock_code or not re.match(r'^[A-Z0-9]{6}$', stock_code):
                continue
                
            if not stock_name or stock_name in ['', 'N/A']:
                continue
            
            # ë°ì´í„° êµ¬ì¡°í™”
            stock_data = {
                'stock_code': stock_code,
                'stock_name': stock_name,
                'market_type': market_type,
                'raw_data': line.strip(),
                'line_number': line_num,
                'file_path': file_path
            }
            
            results.append(stock_data)
            
        except Exception as e:
            print(f"âŒ Error parsing line {line_num} in {file_path}: {e}")
            continue
    
    print(f"âœ… Successfully parsed {len(results)} stocks from {market_type}")
    return results


def sync_domestic_stocks(**context):
    """êµ­ë‚´ì£¼ì‹ì¢…ëª© ë™ê¸°í™” ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸš€ Starting domestic stock synchronization...")
    
    # PostgreSQL ì—°ê²°
    pg_hook = PostgresHook(postgres_conn_id='quantum_postgres')
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    kospi_file = "/opt/airflow/data/kospi_stocks.txt"
    kosdaq_file = "/opt/airflow/data/kosdaq_stocks.txt"
    
    all_stocks = []
    
    try:
        # KOSPI íŒŒì¼ íŒŒì‹±
        if os.path.exists(kospi_file):
            kospi_stocks = parse_domestic_stock_file(kospi_file, 'KOSPI')
            all_stocks.extend(kospi_stocks)
            print(f"ğŸ“ˆ KOSPI stocks parsed: {len(kospi_stocks)}")
        else:
            print("âš ï¸ KOSPI file not found, using sample data")
            # ìƒ˜í”Œ ë°ì´í„°
            sample_kospi = [
                {'stock_code': '005930', 'stock_name': 'ì‚¼ì„±ì „ì', 'market_type': 'KOSPI', 'raw_data': '005930ì‚¼ì„±ì „ì...'},
                {'stock_code': '000660', 'stock_name': 'SKí•˜ì´ë‹‰ìŠ¤', 'market_type': 'KOSPI', 'raw_data': '000660SKí•˜ì´ë‹‰ìŠ¤...'},
            ]
            all_stocks.extend(sample_kospi)
        
        # KOSDAQ íŒŒì¼ íŒŒì‹±
        if os.path.exists(kosdaq_file):
            kosdaq_stocks = parse_domestic_stock_file(kosdaq_file, 'KOSDAQ')
            all_stocks.extend(kosdaq_stocks)
            print(f"ğŸ“Š KOSDAQ stocks parsed: {len(kosdaq_stocks)}")
        else:
            print("âš ï¸ KOSDAQ file not found, using sample data")
            # ìƒ˜í”Œ ë°ì´í„°
            sample_kosdaq = [
                {'stock_code': '035720', 'stock_name': 'ì¹´ì¹´ì˜¤', 'market_type': 'KOSDAQ', 'raw_data': '035720ì¹´ì¹´ì˜¤...'},
            ]
            all_stocks.extend(sample_kosdaq)
        
        if not all_stocks:
            raise ValueError("No stock data to process")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        save_count = save_domestic_stocks_to_db(pg_hook, all_stocks)
        
        print(f"ğŸ‰ Domestic stock sync completed: {save_count} stocks processed")
        
        # XComìœ¼ë¡œ ê²°ê³¼ ì „ë‹¬
        return {
            'total_stocks': len(all_stocks),
            'saved_stocks': save_count,
            'kospi_count': len([s for s in all_stocks if s['market_type'] == 'KOSPI']),
            'kosdaq_count': len([s for s in all_stocks if s['market_type'] == 'KOSDAQ']),
            'sync_time': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Error in domestic stock sync: {e}")
        raise


def save_domestic_stocks_to_db(pg_hook: PostgresHook, stocks: List[Dict[str, Any]]) -> int:
    """êµ­ë‚´ì£¼ì‹ì¢…ëª© ë°ì´í„°ë¥¼ domestic_stocks í…Œì´ë¸”ì— ì €ì¥"""
    
    print(f"ğŸ’¾ Saving {len(stocks)} domestic stocks to database...")
    
    # UPSERT SQL (INSERT ... ON CONFLICT ... UPDATE)
    upsert_sql = """
    INSERT INTO domestic_stocks (
        stock_code,
        stock_name,
        market_type,
        raw_data,
        is_active,
        created_at,
        updated_at
    ) VALUES (
        %(stock_code)s,
        %(stock_name)s,
        %(market_type)s,
        %(raw_data)s,
        true,
        NOW(),
        NOW()
    )
    ON CONFLICT (stock_code) 
    DO UPDATE SET
        stock_name = EXCLUDED.stock_name,
        market_type = EXCLUDED.market_type,
        raw_data = EXCLUDED.raw_data,
        is_active = EXCLUDED.is_active,
        updated_at = NOW();
    """
    
    saved_count = 0
    
    try:
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
        with pg_hook.get_conn() as conn:
            with conn.cursor() as cursor:
                for stock in stocks:
                    try:
                        cursor.execute(upsert_sql, {
                            'stock_code': stock['stock_code'],
                            'stock_name': stock['stock_name'],
                            'market_type': stock['market_type'],
                            'raw_data': stock.get('raw_data', ''),
                        })
                        saved_count += cursor.rowcount
                        
                    except Exception as e:
                        print(f"âŒ Error saving stock {stock['stock_code']}: {e}")
                        continue
                
                conn.commit()
                
    except Exception as e:
        print(f"âŒ Database error: {e}")
        raise
    
    print(f"âœ… Successfully saved {saved_count} domestic stocks")
    return saved_count


def validate_domestic_stock_data(**context):
    """êµ­ë‚´ì£¼ì‹ì¢…ëª© ë°ì´í„° ê²€ì¦"""
    
    print("ğŸ” Validating domestic stock data...")
    
    pg_hook = PostgresHook(postgres_conn_id='quantum_postgres')
    
    try:
        # ê¸°ë³¸ í†µê³„ ì¡°íšŒ
        stats_sql = """
        SELECT 
            market_type,
            COUNT(*) as stock_count,
            COUNT(DISTINCT stock_code) as unique_codes,
            MIN(created_at) as oldest_record,
            MAX(updated_at) as newest_record
        FROM domestic_stocks 
        WHERE is_active = true
        GROUP BY market_type
        ORDER BY market_type;
        """
        
        stats = pg_hook.get_records(stats_sql)
        
        print("ğŸ“Š Domestic Stock Statistics:")
        total_stocks = 0
        for stat in stats:
            market_type, count, unique, oldest, newest = stat
            total_stocks += count
            print(f"  {market_type}: {count} stocks (unique: {unique})")
            print(f"    Oldest: {oldest}, Newest: {newest}")
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        quality_sql = """
        SELECT 
            'duplicate_codes' as issue_type,
            COUNT(*) as issue_count
        FROM (
            SELECT stock_code 
            FROM domestic_stocks 
            WHERE is_active = true
            GROUP BY stock_code 
            HAVING COUNT(*) > 1
        ) duplicates
        
        UNION ALL
        
        SELECT 
            'empty_names' as issue_type,
            COUNT(*) as issue_count
        FROM domestic_stocks 
        WHERE is_active = true 
          AND (stock_name IS NULL OR stock_name = '')
        
        UNION ALL
        
        SELECT 
            'invalid_codes' as issue_type,
            COUNT(*) as issue_count
        FROM domestic_stocks 
        WHERE is_active = true 
          AND stock_code !~ '^[A-Z0-9]{6}$';
        """
        
        quality_results = pg_hook.get_records(quality_sql)
        
        print("ğŸ” Data Quality Check:")
        issues_found = False
        for issue_type, count in quality_results:
            if count > 0:
                issues_found = True
                print(f"  âš ï¸ {issue_type}: {count}")
            else:
                print(f"  âœ… {issue_type}: OK")
        
        if not issues_found:
            print("âœ… All data quality checks passed!")
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            'total_stocks': total_stocks,
            'kospi_stocks': next((s[1] for s in stats if s[0] == 'KOSPI'), 0),
            'kosdaq_stocks': next((s[1] for s in stats if s[0] == 'KOSDAQ'), 0),
            'validation_passed': not issues_found,
            'validation_time': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Validation error: {e}")
        raise


# ========================================
# DAG íƒœìŠ¤í¬ ì •ì˜
# ========================================

# 1. êµ­ë‚´ì£¼ì‹ì¢…ëª© ë™ê¸°í™”
sync_domestic_stocks_task = PythonOperator(
    task_id='sync_domestic_stocks',
    python_callable=sync_domestic_stocks,
    dag=dag,
)

# 2. ë°ì´í„° ê²€ì¦
validate_data_task = PythonOperator(
    task_id='validate_domestic_stock_data',
    python_callable=validate_domestic_stock_data,
    dag=dag,
)

# 3. í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸ (SQL)
update_stats_task = PostgresOperator(
    task_id='update_domestic_stock_stats',
    postgres_conn_id='quantum_postgres',
    sql="""
    -- êµ­ë‚´ì£¼ì‹ì¢…ëª© í†µê³„ ì—…ë°ì´íŠ¸ (UPSERT)
    INSERT INTO airflow.dag_run_stats (
        dag_id,
        task_id,
        execution_date,
        stats_json,
        created_at
    )
    SELECT 
        'domestic_stock_import' as dag_id,
        'update_stats' as task_id,
        '{{ ds }}' as execution_date,
        json_build_object(
            'total_domestic_stocks', COUNT(*),
            'kospi_stocks', COUNT(*) FILTER (WHERE market_type = 'KOSPI'),
            'kosdaq_stocks', COUNT(*) FILTER (WHERE market_type = 'KOSDAQ'),
            'active_stocks', COUNT(*) FILTER (WHERE is_active = true),
            'last_updated', MAX(updated_at)
        ) as stats_json,
        NOW() as created_at
    FROM domestic_stocks
    ON CONFLICT (dag_id, task_id, execution_date)
    DO UPDATE SET
        stats_json = EXCLUDED.stats_json,
        created_at = NOW();
    """,
    dag=dag,
)

# 4. ì„±ê³µ ì•Œë¦¼
success_notification_task = BashOperator(
    task_id='success_notification',
    bash_command='''
    echo "ğŸ‰ êµ­ë‚´ì£¼ì‹ì¢…ëª© ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ!"
    echo "ì‹¤í–‰ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"
    echo "DAG: domestic_stock_import"
    echo "í…Œì´ë¸”: domestic_stocks"
    ''',
    dag=dag,
)

# ========================================
# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì •
# ========================================
sync_domestic_stocks_task >> validate_data_task >> update_stats_task >> success_notification_task