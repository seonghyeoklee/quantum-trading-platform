"""
íŠ¹ì • ì¢…ëª© 2ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ DAG (Stock_Data__17_Custom_Backfill)
- ì‚¬ìš©ìê°€ ì§€ì •í•œ íŠ¹ì • ì¢…ëª©ë“¤ì˜ 2ë…„ì¹˜ íˆìŠ¤í† ë¦¬ ë°ì´í„° ìˆ˜ì§‘
- ìˆ˜ë™ ì‹¤í–‰ìœ¼ë¡œ í•„ìš”í•  ë•Œë§Œ ì‘ë™
- UPSERT ë°©ì‹ìœ¼ë¡œ ì¤‘ë³µ ë°ì´í„° ìë™ ê´€ë¦¬
- ì‹¤ì œ KIS API ì—°ë™
"""

import os
import json
import time
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pytz

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import DagRun


# ========================================
# DAG ì„¤ì •
# ========================================
default_args = {
    'owner': 'quantum-trading',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 9, tzinfo=pytz.timezone("Asia/Seoul")),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=15),
    'execution_timeout': timedelta(hours=6),
}

dag = DAG(
    dag_id='Stock_Data__17_Custom_Backfill',
    default_args=default_args,
    description='íŠ¹ì • ì¢…ëª© 2ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ - ì‚¬ìš©ì ì§€ì • ì¢…ëª©ë“¤ì˜ íˆìŠ¤í† ë¦¬ ë°ì´í„° ë°±í•„ (ìˆ˜ë™ ì‹¤í–‰)',
    schedule_interval=None,  # ìˆ˜ë™ ì‹¤í–‰ë§Œ
    max_active_runs=1,
    catchup=False,
    tags=['custom-backfill', 'manual', 'historical-data', 'kis-api', 'user-specified'],
    params={
        "stock_codes": ["005930", "000660", "035720"],  # ê¸°ë³¸ê°’: ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ì¹´ì¹´ì˜¤
        "period_days": 730,  # ê¸°ë³¸ê°’: 2ë…„
        "batch_size": 20,    # ë°°ì¹˜ í¬ê¸°
    }
)

# ========================================
# ìƒìˆ˜ ì •ì˜
# ========================================

# ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
DEFAULT_BATCH_SIZE = 20
DEFAULT_PERIOD_DAYS = 730  # 2ë…„
REQUEST_DELAY = 0.05  # 50ms API í˜¸ì¶œ ê°„ê²©
BATCH_DELAY = 15  # ë°°ì¹˜ ê°„ 15ì´ˆ ëŒ€ê¸°

# ========================================
# KIS API í´ë¼ì´ì–¸íŠ¸ (ì»¤ìŠ¤í…€ ë°±í•„ìš©)
# ========================================

class KISCustomBackfillClient:
    """ì»¤ìŠ¤í…€ ë°±í•„ìš© KIS API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.adapter_base_url = "http://host.docker.internal:8000"
        self.request_delay = REQUEST_DELAY
        self.success_count = 0
        self.error_count = 0
    
    def get_historical_data(self, stock_code: str, retries: int = 3) -> Optional[Dict]:
        """2ë…„ì¹˜ íˆìŠ¤í† ë¦¬ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ í¬í•¨)"""
        for attempt in range(retries):
            try:
                print(f"ğŸ” [{attempt+1}/{retries}] {stock_code} 2ë…„ì¹˜ ë°ì´í„° ì¡°íšŒ...")
                
                url = f"{self.adapter_base_url}/domestic/chart/{stock_code}"
                params = {
                    'period': 'D',  # ì¼ë´‰
                    'adj_price': 1  # ìˆ˜ì •ì£¼ê°€
                }
                
                response = requests.get(url, params=params, timeout=30)
                response.raise_for_status()
                
                kis_data = response.json()
                
                # KIS API ì‘ë‹µ ê²€ì¦
                if kis_data.get('rt_cd') != '0':
                    if attempt == 0:  # ì²« ë²ˆì§¸ ì‹œë„ì—ì„œë§Œ ë¡œê·¸
                        print(f"âŒ {stock_code}: KIS API ì˜¤ë¥˜ - {kis_data.get('msg1', 'Unknown')}")
                    return None
                
                if not kis_data.get('output2'):
                    if attempt == 0:
                        print(f"âŒ {stock_code}: output2 ë°ì´í„° ì—†ìŒ")
                    return None
                
                chart_data = kis_data['output2']
                print(f"âœ… {stock_code}: KIS APIì—ì„œ {len(chart_data)}ì¼ ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
                
                self.success_count += 1
                time.sleep(self.request_delay)
                return kis_data
                
            except Exception as e:
                if attempt == retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë§Œ ì—ëŸ¬ ì¹´ìš´íŠ¸
                    self.error_count += 1
                    print(f"âŒ {stock_code} ìµœì¢… ì‹¤íŒ¨: {e}")
                else:
                    wait_time = (attempt + 1) * 2  # 2ì´ˆ, 4ì´ˆ, 6ì´ˆ ëŒ€ê¸°
                    print(f"ğŸ”„ {stock_code} ì¬ì‹œë„ ì „ {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
        
        return None

# ========================================
# í•µì‹¬ í•¨ìˆ˜ë“¤
# ========================================

def validate_custom_stocks(**context):
    """ì‚¬ìš©ìê°€ ì§€ì •í•œ ì¢…ëª©ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦"""
    
    print("ğŸ” ì‚¬ìš©ì ì§€ì • ì¢…ëª© ìœ íš¨ì„± ê²€ì¦ ì‹œì‘...")
    
    # DAG ì‹¤í–‰ ì‹œ ì „ë‹¬ëœ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    dag_run: DagRun = context['dag_run']
    conf = dag_run.conf or {}
    
    stock_codes = conf.get('stock_codes', dag.params['stock_codes'])
    period_days = conf.get('period_days', dag.params['period_days'])
    batch_size = conf.get('batch_size', dag.params['batch_size'])
    
    print(f"ğŸ“Š ìš”ì²­ëœ ì„¤ì •:")
    print(f"  - ì¢…ëª© ì½”ë“œ: {stock_codes}")
    print(f"  - ìˆ˜ì§‘ ê¸°ê°„: {period_days}ì¼")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    
    if not stock_codes or len(stock_codes) == 0:
        raise ValueError("ì¢…ëª© ì½”ë“œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # PostgreSQL ì—°ê²°
    pg_hook = PostgresHook(postgres_conn_id='quantum_postgres')
    
    # domestic_stocksì—ì„œ ì¢…ëª© ìœ íš¨ì„± ê²€ì¦
    placeholders = ','.join(['%s'] * len(stock_codes))
    validation_sql = f"""
    SELECT stock_code, stock_name, market_type, is_active
    FROM domestic_stocks 
    WHERE stock_code IN ({placeholders})
    ORDER BY market_type, stock_code;
    """
    
    valid_stocks = pg_hook.get_records(validation_sql, parameters=stock_codes)
    
    valid_stock_codes = [row[0] for row in valid_stocks]
    invalid_codes = [code for code in stock_codes if code not in valid_stock_codes]
    inactive_stocks = [row for row in valid_stocks if not row[3]]  # is_activeê°€ Falseì¸ ê²ƒë“¤
    
    print(f"ğŸ“ˆ ì¢…ëª© ê²€ì¦ ê²°ê³¼:")
    print(f"  - ìœ íš¨í•œ ì¢…ëª©: {len(valid_stock_codes)}ê°œ")
    print(f"  - ë¬´íš¨í•œ ì¢…ëª©: {len(invalid_codes)}ê°œ")
    print(f"  - ë¹„í™œì„± ì¢…ëª©: {len(inactive_stocks)}ê°œ")
    
    if invalid_codes:
        print(f"âš ï¸ ë¬´íš¨í•œ ì¢…ëª© ì½”ë“œ: {invalid_codes}")
    
    if inactive_stocks:
        inactive_codes = [row[0] for row in inactive_stocks]
        print(f"âš ï¸ ë¹„í™œì„± ì¢…ëª©: {inactive_codes}")
    
    if not valid_stock_codes:
        raise ValueError("ìœ íš¨í•œ ì¢…ëª©ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìœ íš¨í•œ ì¢…ëª© ì •ë³´ë¥¼ êµ¬ì¡°í™”
    validated_stocks = []
    for row in valid_stocks:
        if row[3]:  # í™œì„± ì¢…ëª©ë§Œ
            validated_stocks.append({
                'stock_code': row[0],
                'stock_name': row[1],
                'market_type': row[2],
                'is_active': row[3]
            })
    
    # XComìœ¼ë¡œ ê²€ì¦ëœ ì •ë³´ ì „ë‹¬
    context['task_instance'].xcom_push(key='validated_stocks', value=validated_stocks)
    context['task_instance'].xcom_push(key='period_days', value=period_days)
    context['task_instance'].xcom_push(key='batch_size', value=batch_size)
    
    return {
        'total_requested': len(stock_codes),
        'valid_stocks_count': len(validated_stocks),
        'invalid_codes': invalid_codes,
        'inactive_codes': [row[0] for row in inactive_stocks],
        'validated_stocks': validated_stocks[:5],  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
        'validation_time': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
    }


def fetch_custom_stock_data(**context):
    """ì‚¬ìš©ì ì§€ì • ì¢…ëª©ë“¤ì˜ 2ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘"""
    
    print("ğŸš€ ì»¤ìŠ¤í…€ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    # XComì—ì„œ ê²€ì¦ëœ ì¢…ëª© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    validated_stocks = context['task_instance'].xcom_pull(key='validated_stocks', task_ids='validate_custom_stocks')
    batch_size = context['task_instance'].xcom_pull(key='batch_size', task_ids='validate_custom_stocks')
    
    if not validated_stocks:
        print("âœ… ìˆ˜ì§‘í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {'collected_count': 0, 'total_records': 0}
    
    print(f"ğŸ“¦ {len(validated_stocks)}ê°œ ì¢…ëª©ì„ {batch_size}ê°œì”© ë°°ì¹˜ ì²˜ë¦¬...")
    
    # KIS API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    kis_client = KISCustomBackfillClient()
    pg_hook = PostgresHook(postgres_conn_id='quantum_postgres')
    
    total_collected = 0
    total_records = 0
    total_errors = 0
    
    # ë°°ì¹˜ë³„ ì²˜ë¦¬
    for i in range(0, len(validated_stocks), batch_size):
        batch = validated_stocks[i:i+batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(validated_stocks) - 1) // batch_size + 1
        
        print(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches}: {len(batch)}ê°œ ì¢…ëª© ì²˜ë¦¬ ì¤‘...")
        
        batch_collected = 0
        batch_records = 0
        
        for stock in batch:
            stock_code = stock['stock_code']
            stock_name = stock['stock_name']
            
            try:
                print(f"ğŸ”„ {stock_code} ({stock_name}) ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
                
                # 2ë…„ì¹˜ ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ
                chart_response = kis_client.get_historical_data(stock_code)
                
                if chart_response and chart_response.get('rt_cd') == '0':
                    chart_data = chart_response['output2']
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    saved_count = save_custom_backfill_to_db(pg_hook, stock_code, chart_data, chart_response)
                    total_records += saved_count
                    batch_collected += 1
                    batch_records += saved_count
                    
                    print(f"âœ… {stock_code}: {saved_count}ì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                    
                else:
                    print(f"âŒ {stock_code}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    total_errors += 1
                    
            except Exception as e:
                print(f"âŒ {stock_code} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                total_errors += 1
                continue
        
        total_collected += batch_collected
        
        print(f"  ë°°ì¹˜ {batch_num} ì™„ë£Œ: {batch_collected}/{len(batch)}ê°œ ìˆ˜ì§‘, {batch_records:,}ê±´ ì €ì¥")
        
        # ë°°ì¹˜ ê°„ íœ´ì‹ (ë§ˆì§€ë§‰ ë°°ì¹˜ ì œì™¸)
        if i + batch_size < len(validated_stocks):
            print(f"â¸ï¸ {BATCH_DELAY}ì´ˆ íœ´ì‹...")
            time.sleep(BATCH_DELAY)
    
    result = {
        'collected_count': total_collected,
        'total_records': total_records,
        'error_count': total_errors,
        'api_success_count': kis_client.success_count,
        'api_error_count': kis_client.error_count,
        'collection_time': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
    }
    
    print(f"ğŸ‰ ì»¤ìŠ¤í…€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {total_collected}ê°œ ì¢…ëª©, {total_records:,}ê±´ ì €ì¥")
    print(f"ğŸ“Š API í˜¸ì¶œ ê²°ê³¼: {kis_client.success_count}ê°œ ì„±ê³µ, {kis_client.error_count}ê°œ ì‹¤íŒ¨")
    
    return result


def save_custom_backfill_to_db(pg_hook: PostgresHook, stock_code: str, chart_data: List[Dict], full_response: Dict) -> int:
    """ì»¤ìŠ¤í…€ ë°±í•„ ë°ì´í„°ë¥¼ domestic_stocks_detailì— UPSERTë¡œ ì €ì¥"""
    
    if not chart_data:
        return 0
    
    # UPSERT SQL (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒì„±)
    upsert_sql = """
    INSERT INTO domestic_stocks_detail (
        stock_code,
        trade_date,
        current_price,
        volume,
        data_type,
        api_endpoint,
        raw_response,
        request_params,
        request_timestamp,
        created_at,
        updated_at,
        response_code,
        data_quality
    ) VALUES (
        %(stock_code)s,
        TO_DATE(%(trade_date)s, 'YYYYMMDD'),
        %(close_price)s,
        %(volume)s,
        'CHART',
        '/uapi/domestic-stock/v1/quotations/inquire-daily-price',
        %(raw_response)s,
        %(request_params)s,
        NOW(),
        NOW(),
        NOW(),
        '0',
        'EXCELLENT'
    )
    ON CONFLICT (stock_code, trade_date, data_type)
    DO UPDATE SET
        current_price = EXCLUDED.current_price,
        volume = EXCLUDED.volume,
        raw_response = EXCLUDED.raw_response,
        request_params = EXCLUDED.request_params,
        request_timestamp = EXCLUDED.request_timestamp,
        updated_at = NOW(),
        data_quality = 'EXCELLENT',
        response_code = '0';
    """
    
    saved_count = 0
    
    try:
        with pg_hook.get_conn() as conn:
            with conn.cursor() as cursor:
                for daily_data in chart_data:
                    try:
                        # OHLCV ë°ì´í„° ì¶”ì¶œ
                        ohlcv_data = {
                            'open': int(daily_data['stck_oprc']),
                            'high': int(daily_data['stck_hgpr']),
                            'low': int(daily_data['stck_lwpr']),
                            'close': int(daily_data['stck_clpr']),
                            'volume': int(daily_data['acml_vol']),
                        }
                        
                        cursor.execute(upsert_sql, {
                            'stock_code': stock_code,
                            'trade_date': daily_data['stck_bsop_date'],
                            'close_price': ohlcv_data['close'],
                            'volume': ohlcv_data['volume'],
                            'raw_response': json.dumps({
                                **daily_data,
                                'ohlcv': ohlcv_data,
                                'custom_backfill_source': 'custom_stock_backfill_dag',
                                'backfill_timestamp': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
                            }),
                            'request_params': json.dumps({
                                'stock_code': stock_code,
                                'period': '2years_custom',
                                'data_type': 'custom_backfill',
                                'source': 'user_specified_backfill'
                            }),
                        })
                        saved_count += 1
                        
                    except Exception as e:
                        print(f"âŒ {stock_code} {daily_data.get('stck_bsop_date', 'unknown')} ì €ì¥ ì˜¤ë¥˜: {e}")
                        continue
                
                conn.commit()
                
    except Exception as e:
        print(f"âŒ {stock_code} ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ ì˜¤ë¥˜: {e}")
        raise
    
    return saved_count


def validate_custom_results(**context):
    """ì»¤ìŠ¤í…€ ë°±í•„ ê²°ê³¼ ê²€ì¦"""
    
    print("ğŸ” ì»¤ìŠ¤í…€ ë°±í•„ ê²°ê³¼ ê²€ì¦ ì‹œì‘...")
    
    pg_hook = PostgresHook(postgres_conn_id='quantum_postgres')
    
    # ìˆ˜ì§‘ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    collection_result = context['task_instance'].xcom_pull(task_ids='fetch_custom_stock_data') or {}
    validated_stocks = context['task_instance'].xcom_pull(key='validated_stocks', task_ids='validate_custom_stocks')
    
    collected_count = collection_result.get('collected_count', 0)
    total_records = collection_result.get('total_records', 0)
    
    # ì˜¤ëŠ˜ ì €ì¥ëœ ì»¤ìŠ¤í…€ ë°±í•„ ë°ì´í„° í™•ì¸
    today_sql = """
    SELECT 
        COUNT(DISTINCT stock_code) as updated_stocks,
        COUNT(*) as updated_records,
        MIN(trade_date) as earliest_date,
        MAX(trade_date) as latest_date
    FROM domestic_stocks_detail 
    WHERE DATE(created_at) = CURRENT_DATE
    AND data_type = 'CHART'
    AND raw_response::text LIKE '%custom_backfill_source%';
    """
    
    today_stats = pg_hook.get_first(today_sql)
    today_updated_stocks, today_updated_records, earliest_date, latest_date = today_stats
    
    # ê°œë³„ ì¢…ëª© ë°ì´í„° í™•ì¸
    if validated_stocks:
        stock_codes = [stock['stock_code'] for stock in validated_stocks]
        placeholders = ','.join(['%s'] * len(stock_codes))
        
        individual_sql = f"""
        SELECT 
            stock_code,
            COUNT(*) as record_count,
            MIN(trade_date) as earliest_date,
            MAX(trade_date) as latest_date
        FROM domestic_stocks_detail 
        WHERE stock_code IN ({placeholders})
        AND data_type = 'CHART'
        GROUP BY stock_code
        ORDER BY record_count DESC;
        """
        
        individual_stats = pg_hook.get_records(individual_sql, parameters=stock_codes)
        
        print(f"ğŸ“ˆ ê°œë³„ ì¢…ëª© ë°ì´í„° í˜„í™©:")
        for stock_code, record_count, earliest, latest in individual_stats[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            stock_name = next((s['stock_name'] for s in validated_stocks if s['stock_code'] == stock_code), 'Unknown')
            print(f"  - {stock_code} ({stock_name}): {record_count:,}ê±´ ({earliest} ~ {latest})")
        
        if len(individual_stats) > 5:
            print(f"  ... ë° {len(individual_stats)-5}ê°œ ë”")
    
    validation_result = {
        'requested_stocks': len(validated_stocks) if validated_stocks else 0,
        'collected_stocks': collected_count,
        'total_records_saved': total_records,
        'today_updated_stocks': today_updated_stocks or 0,
        'today_updated_records': today_updated_records or 0,
        'data_date_range': {
            'earliest': str(earliest_date) if earliest_date else None,
            'latest': str(latest_date) if latest_date else None
        },
        'success_rate': round(collected_count / len(validated_stocks) * 100, 1) if validated_stocks else 0,
        'validation_time': datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
    }
    
    print(f"ğŸ¯ ì»¤ìŠ¤í…€ ë°±í•„ ê²€ì¦ ê²°ê³¼:")
    print(f"  - ìš”ì²­ ì¢…ëª©: {validation_result['requested_stocks']}ê°œ")
    print(f"  - ìˆ˜ì§‘ ì™„ë£Œ: {validation_result['collected_stocks']}ê°œ")
    print(f"  - ì„±ê³µë¥ : {validation_result['success_rate']}%")
    print(f"  - ì €ì¥ëœ ë ˆì½”ë“œ: {validation_result['total_records_saved']:,}ê±´")
    print(f"  - ë°ì´í„° ë²”ìœ„: {validation_result['data_date_range']['earliest']} ~ {validation_result['data_date_range']['latest']}")
    
    return validation_result


# ========================================
# DAG íƒœìŠ¤í¬ ì •ì˜
# ========================================

# 1. ì‚¬ìš©ì ì§€ì • ì¢…ëª© ìœ íš¨ì„± ê²€ì¦
validate_stocks_task = PythonOperator(
    task_id='validate_custom_stocks',
    python_callable=validate_custom_stocks,
    dag=dag,
)

# 2. ì»¤ìŠ¤í…€ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘
fetch_data_task = PythonOperator(
    task_id='fetch_custom_stock_data',
    python_callable=fetch_custom_stock_data,
    dag=dag,
)

# 3. ìˆ˜ì§‘ ê²°ê³¼ ê²€ì¦
validate_results_task = PythonOperator(
    task_id='validate_custom_results',
    python_callable=validate_custom_results,
    dag=dag,
)

# 4. ì™„ë£Œ ì•Œë¦¼
completion_notification_task = BashOperator(
    task_id='completion_notification',
    bash_command='''
    echo "ğŸ‰ íŠ¹ì • ì¢…ëª© 2ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!"
    echo "ì‹¤í–‰ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"
    echo "DAG: Stock_Data__17_Custom_Backfill"
    echo "ì‹¤í–‰ ë°©ì‹: ìˆ˜ë™ ì‹¤í–‰ (ì‚¬ìš©ì ì§€ì • ì¢…ëª©)"
    echo "ë°ì´í„° ì²˜ë¦¬: UPSERT ë°©ì‹ìœ¼ë¡œ ì¤‘ë³µ ìë™ ê´€ë¦¬"
    ''',
    dag=dag,
)

# ========================================
# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì •
# ========================================
validate_stocks_task >> fetch_data_task >> validate_results_task >> completion_notification_task