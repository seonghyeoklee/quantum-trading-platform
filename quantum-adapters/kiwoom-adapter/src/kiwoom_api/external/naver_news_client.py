"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í´ë¼ì´ì–¸íŠ¸

ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì˜ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬
í•©ë²•ì ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
"""

import asyncio
import httpx
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
from urllib.parse import quote


class NaverNewsClient:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        # ê°œë°œ ëª¨ë“œ (API í‚¤ê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš° ëª©ì—… ë°ì´í„° ì‚¬ìš©)
        self.dev_mode = (not client_id or not client_secret or 
                        client_id == "" or client_secret == "" or
                        client_id.strip() == "" or client_secret.strip() == "")
        
        self.headers = {
            'X-Naver-Client-Id': self.client_id,
            'X-Naver-Client-Secret': self.client_secret,
            'User-Agent': 'Kiwoom-Adapter/1.0'
        }
        self.timeout = httpx.Timeout(15.0)
    
    async def search_news(
        self, 
        query: str, 
        display: int = 20, 
        start: int = 1, 
        sort: str = "date"
    ) -> Dict[str, Any]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ
        
        Args:
            query: ê²€ìƒ‰ì–´ (UTF-8 ì¸ì½”ë”©)
            display: ê²°ê³¼ ê°œìˆ˜ (1~100, ê¸°ë³¸ê°’: 20)
            start: ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000, ê¸°ë³¸ê°’: 1)
            sort: ì •ë ¬ ë°©ì‹ ("sim": ì •í™•ë„ìˆœ, "date": ë‚ ì§œìˆœ)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ê°œë°œ ëª¨ë“œ: ëª©ì—… ë°ì´í„° ë°˜í™˜
            if self.dev_mode:
                print(f"ğŸ”§ [DEV MODE] ë„¤ì´ë²„ API í‚¤ê°€ ì—†ì–´ ëª©ì—… ë°ì´í„° ë°˜í™˜: {query}")
                return self._get_mock_data(query, display, start)
            
            # URL ì¸ì½”ë”©
            encoded_query = quote(query, safe='', encoding='utf-8')
            
            params = {
                "query": encoded_query,
                "display": min(display, 100),
                "start": max(1, start),
                "sort": sort if sort in ["sim", "date"] else "date"
            }
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(
                    self.base_url,
                    params=params,
                    headers=self.headers
                )
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 401:
                    print(f"âŒ ë„¤ì´ë²„ API ì¸ì¦ ì˜¤ë¥˜ (401): Client ID/Secretì„ í™•ì¸í•˜ì„¸ìš”")
                    print(f"   í˜„ì¬ Client ID: {self.client_id[:10]}...")
                    return {"items": [], "total": 0, "start": start, "display": display}
                elif response.status_code == 403:
                    print(f"âŒ ë„¤ì´ë²„ API ê¶Œí•œ ì˜¤ë¥˜ (403): API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”")
                    return {"items": [], "total": 0, "start": start, "display": display}
                elif response.status_code == 400:
                    print(f"âŒ ë„¤ì´ë²„ API ìš”ì²­ ì˜¤ë¥˜ (400): {response.text}")
                    return {"items": [], "total": 0, "start": start, "display": display}
                else:
                    print(f"âŒ ë„¤ì´ë²„ API ì˜¤ë¥˜ ({response.status_code}): {response.text}")
                    return {"items": [], "total": 0, "start": start, "display": display}
                    
        except httpx.TimeoutException:
            print(f"âŒ ë„¤ì´ë²„ API íƒ€ì„ì•„ì›ƒ: {query}")
            return {"items": [], "total": 0, "start": start, "display": display}
        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return {"items": [], "total": 0, "start": start, "display": display}
    
    def clean_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        if not text:
            return ""
        # <b> íƒœê·¸ì™€ ê¸°íƒ€ HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        # HTML ì—”í‹°í‹° ì²˜ë¦¬
        clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>')
        clean_text = clean_text.replace('&amp;', '&').replace('&quot;', '"')
        clean_text = clean_text.replace('&apos;', "'")
        return clean_text.strip()
    
    def parse_pubdate(self, pubdate: str) -> str:
        """ë„¤ì´ë²„ API pubDateë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # "Mon, 26 Sep 2016 07:50:00 +0900" -> "2016-09-26"
            dt = datetime.strptime(pubdate, "%a, %d %b %Y %H:%M:%S %z")
            return dt.strftime("%Y-%m-%d")
        except:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ë‚ ì§œ ë°˜í™˜
            return datetime.now().strftime("%Y-%m-%d")
    
    def analyze_sentiment(self, title: str, description: str = "") -> str:
        """ê°„ë‹¨í•œ ê°ì • ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)"""
        text = f"{title} {description}".lower()
        
        positive_keywords = [
            'ìƒìŠ¹', 'í˜¸ì¬', 'ê°œì„ ', 'ì„±ì¥', 'ì¦ê°€', 'í™•ëŒ€', 'íˆ¬ì', 'ê³„ì•½', 'ìˆ˜ì£¼', 
            'ìƒí•œê°€', 'ê¸‰ë“±', 'ê¸°ëŒ€', 'ì „ë§', 'ì¢‹ì€', 'ìš°ìˆ˜', 'ì„±ê³µ', 'ë°œí‘œ',
            'ê¸ì •', 'í”ŒëŸ¬ìŠ¤', 'ìƒí–¥', 'ëŒíŒŒ', 'ì‹ ê³ ê°€'
        ]
        
        negative_keywords = [
            'í•˜ë½', 'ì•…ì¬', 'ê°ì†Œ', 'ì¶•ì†Œ', 'ë¦¬ìŠ¤í¬', 'ìš°ë ¤', 'í•˜í•œê°€', 'ê¸‰ë½', 
            'ì†ì‹¤', 'ì ì', 'ë¶€ì§„', 'ì–´ë ¤ì›€', 'ë¬¸ì œ', 'ìœ„ê¸°', 'ì‹¤ë§', 'ë¶€ì •',
            'ë§ˆì´ë„ˆìŠ¤', 'í•˜í–¥', 'í­ë½', 'ì‹ ì €ê°€'
        ]
        
        positive_count = sum(1 for keyword in positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in negative_keywords if keyword in text)
        
        if positive_count > negative_count:
            return "ê¸ì •"
        elif negative_count > positive_count:
            return "ë¶€ì •"
        else:
            return "ì¤‘ë¦½"
    
    def convert_to_enhanced_format(
        self, 
        api_response: Dict[str, Any], 
        stock_code: str, 
        stock_name: str
    ) -> Dict[str, Any]:
        """
        ë„¤ì´ë²„ API ì‘ë‹µì„ ê¸°ì¡´ enhanced_news_crawler í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        items = api_response.get("items", [])
        total = api_response.get("total", 0)
        
        articles = []
        category_stats = {"ë„¤ì´ë²„ë‰´ìŠ¤API": len(items)}
        
        for item in items:
            # HTML íƒœê·¸ ì œê±°
            clean_title = self.clean_html_tags(item.get("title", ""))
            clean_description = self.clean_html_tags(item.get("description", ""))
            
            # ë‚ ì§œ íŒŒì‹±
            pub_date = self.parse_pubdate(item.get("pubDate", ""))
            
            # ê°ì • ë¶„ì„
            sentiment = self.analyze_sentiment(clean_title, clean_description)
            
            article = {
                "title": clean_title,
                "url": item.get("originallink", item.get("link", "")),
                "link": item.get("link", item.get("originallink", "")),
                "content": clean_description,
                "summary": clean_description[:100] + "..." if len(clean_description) > 100 else clean_description,
                "date": pub_date,
                "source": "ë„¤ì´ë²„ë‰´ìŠ¤API",
                "sentiment": sentiment,
                "category": "ê²€ìƒ‰ê²°ê³¼"
            }
            
            articles.append(article)
        
        # ê°ì„± ë¶„ì„ í†µê³„ ê³„ì‚°
        sentiment_summary = self._calculate_sentiment_summary(articles)
        
        # ì£¼ìš” í…Œë§ˆ ì¶”ì¶œ
        key_themes = self._extract_key_themes(articles)
        
        return {
            "articles": articles,
            "total_count": len(articles),
            "category_stats": category_stats,
            "sentiment_summary": sentiment_summary,
            "key_themes": key_themes,
            "stock_code": stock_code,
            "stock_name": stock_name,
            "collected_at": datetime.now().isoformat(),
            "api_total": total  # APIì—ì„œ ë°˜í™˜í•œ ì´ ê²°ê³¼ ìˆ˜
        }
    
    def _calculate_sentiment_summary(self, news_list: List[Dict]) -> Dict[str, Any]:
        """ê°ì„± ë¶„ì„ ìš”ì•½ í†µê³„"""
        if not news_list:
            return {"positive": 0, "neutral": 0, "negative": 0, "overall": "ì¤‘ë¦½"}
        
        sentiment_count = {"ê¸ì •": 0, "ì¤‘ë¦½": 0, "ë¶€ì •": 0}
        
        for news in news_list:
            sentiment = news.get('sentiment', 'ì¤‘ë¦½')
            sentiment_count[sentiment] = sentiment_count.get(sentiment, 0) + 1
        
        total = len(news_list)
        positive_ratio = sentiment_count["ê¸ì •"] / total
        negative_ratio = sentiment_count["ë¶€ì •"] / total
        
        if positive_ratio > 0.6:
            overall = "ë§¤ìš° ê¸ì •ì "
        elif positive_ratio > 0.4:
            overall = "ê¸ì •ì "
        elif negative_ratio > 0.6:
            overall = "ë§¤ìš° ë¶€ì •ì "
        elif negative_ratio > 0.4:
            overall = "ë¶€ì •ì "
        else:
            overall = "ì¤‘ë¦½"
        
        return {
            "positive": sentiment_count["ê¸ì •"],
            "neutral": sentiment_count["ì¤‘ë¦½"],
            "negative": sentiment_count["ë¶€ì •"],
            "overall": overall
        }
    
    def _extract_key_themes(self, news_list: List[Dict]) -> List[str]:
        """ì£¼ìš” í…Œë§ˆ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not news_list:
            return []
        
        theme_keywords = [
            'ì‹¤ì ', 'íˆ¬ì', 'ê°œë°œ', 'ê³„ì•½', 'ìˆ˜ì£¼', 'ì¸ìˆ˜', 'í•©ë³‘', 
            'ìƒì¥', 'ì¦ì', 'ë°°ë‹¹', 'ì‹ ì œí’ˆ', 'ê¸°ìˆ ', 'íŠ¹í—ˆ', 'ìŠ¹ì¸',
            'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ì„±ì¥', 'í™•ì¥'
        ]
        
        theme_count = {}
        for news in news_list:
            title = news.get('title', '')
            content = news.get('content', '')
            text = f"{title} {content}"
            
            for keyword in theme_keywords:
                if keyword in text:
                    theme_count[keyword] = theme_count.get(keyword, 0) + 1
        
        # ìƒìœ„ 3ê°œ í…Œë§ˆ ë°˜í™˜
        sorted_themes = sorted(theme_count.items(), key=lambda x: x[1], reverse=True)
        return [theme for theme, count in sorted_themes[:3] if count > 0]
    
    def _get_mock_data(self, query: str, display: int, start: int) -> Dict[str, Any]:
        """ê°œë°œ ëª¨ë“œìš© ëª©ì—… ë°ì´í„° ìƒì„±"""
        from datetime import datetime, timedelta
        import random
        
        # ê¸°ë³¸ ëª©ì—… ë‰´ìŠ¤ í…œí”Œë¦¿
        mock_news = [
            {
                "title": f"<b>{query}</b> ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ - ì‹¤ì  ë°œí‘œ ì˜ˆì •",
                "originallink": "https://example.com/news1",
                "link": "https://search.naver.com/news1",
                "description": f"<b>{query}</b> ê¸°ì—…ì´ ì˜¬í•´ 3ë¶„ê¸° ì‹¤ì ì„ ë°œí‘œí•  ì˜ˆì •ì´ë¼ê³  ë°í˜”ë‹¤. ì‹œì¥ì—ì„œëŠ” ê¸ì •ì ì¸ ì‹¤ì ì„ ê¸°ëŒ€í•˜ê³  ìˆë‹¤.",
                "pubDate": (datetime.now() - timedelta(hours=2)).strftime("%a, %d %b %Y %H:%M:%S +0900")
            },
            {
                "title": f"<b>{query}</b> ì£¼ê°€ ìƒìŠ¹ì„¸, íˆ¬ììë“¤ ê´€ì‹¬ ì§‘ì¤‘",
                "originallink": "https://example.com/news2", 
                "link": "https://search.naver.com/news2",
                "description": f"<b>{query}</b> ì£¼ì‹ì´ ìµœê·¼ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ë©° íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤. ì „ë¬¸ê°€ë“¤ì€ í–¥í›„ ì „ë§ì— ëŒ€í•´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í–ˆë‹¤.",
                "pubDate": (datetime.now() - timedelta(hours=5)).strftime("%a, %d %b %Y %H:%M:%S +0900")
            },
            {
                "title": f"<b>{query}</b> ì‹ ê¸°ìˆ  ê°œë°œë¡œ ë¯¸ë˜ ì„±ì¥ ê°€ëŠ¥ì„± ë†’ì•„ì ¸",
                "originallink": "https://example.com/news3",
                "link": "https://search.naver.com/news3", 
                "description": f"<b>{query}</b>ê°€ ìƒˆë¡œìš´ ê¸°ìˆ  ê°œë°œì— ì„±ê³µí•˜ë©° ë¯¸ë˜ ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì¡Œë‹¤ëŠ” ë¶„ì„ì´ ë‚˜ì™”ë‹¤.",
                "pubDate": (datetime.now() - timedelta(hours=8)).strftime("%a, %d %b %Y %H:%M:%S +0900")
            },
            {
                "title": f"<b>{query}</b> ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€, ê²½ìŸë ¥ ê°•í™”",
                "originallink": "https://example.com/news4",
                "link": "https://search.naver.com/news4",
                "description": f"<b>{query}</b>ì˜ ì‹œì¥ ì ìœ ìœ¨ì´ ì§€ì†ì ìœ¼ë¡œ í™•ëŒ€ë˜ê³  ìˆì–´ ê²½ìŸë ¥ì´ ê°•í™”ë˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.",
                "pubDate": (datetime.now() - timedelta(hours=12)).strftime("%a, %d %b %Y %H:%M:%S +0900")
            },
            {
                "title": f"<b>{query}</b> ê´€ë ¨ ì—…ê³„ ë™í–¥ ë° ì „ë§ ë¶„ì„",
                "originallink": "https://example.com/news5",
                "link": "https://search.naver.com/news5",
                "description": f"<b>{query}</b> ê´€ë ¨ ì—…ê³„ì˜ ìµœì‹  ë™í–¥ê³¼ í–¥í›„ ì „ë§ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì´ ê³µê°œë˜ì—ˆë‹¤.",
                "pubDate": (datetime.now() - timedelta(days=1)).strftime("%a, %d %b %Y %H:%M:%S +0900")
            }
        ]
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ê³ ë ¤í•´ì„œ ê²°ê³¼ ìŠ¬ë¼ì´ì‹±
        end_index = start + display - 1
        selected_news = mock_news[start-1:end_index] if start <= len(mock_news) else []
        
        return {
            "total": len(mock_news),
            "start": start,
            "display": len(selected_news),
            "items": selected_news
        }


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_naver_news_client():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    from ..config.settings import settings
    
    if not settings.NAVER_CLIENT_ID or not settings.NAVER_CLIENT_SECRET:
        print("âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
    
    client = NaverNewsClient(
        client_id=settings.NAVER_CLIENT_ID,
        client_secret=settings.NAVER_CLIENT_SECRET
    )
    
    # ì˜ˆì‹œ: ë‰´ìŠ¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "{ì¢…ëª©ëª…} OR {ì¢…ëª©ì½”ë“œ}"
    result = await client.search_news(query, display=5)
    
    if result.get("items"):
        print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"ğŸ“Š ì´ {result.get('total', 0)}ê±´ ì¤‘ {len(result.get('items', []))}ê±´ ì¡°íšŒ")
        
        first_item = result["items"][0]
        print(f"ğŸ—ï¸ ì²« ë²ˆì§¸ ë‰´ìŠ¤: {client.clean_html_tags(first_item.get('title', ''))}")
        
        # enhanced í˜•ì‹ ë³€í™˜ í…ŒìŠ¤íŠ¸
        enhanced_result = client.convert_to_enhanced_format(result, "{ì¢…ëª©ì½”ë“œ}", "{ì¢…ëª©ëª…}")
        print(f"ğŸ”„ ë³€í™˜ ê²°ê³¼: {len(enhanced_result['articles'])}ê±´ ë³€í™˜ ì™„ë£Œ")
        
        return enhanced_result
    else:
        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print(f"ğŸ“„ ì‘ë‹µ: {result}")
        return None


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
    result = asyncio.run(test_naver_news_client())
    if result:
        print(f"\nìµœì¢… ê²°ê³¼:")
        print(f"- ì´ ë‰´ìŠ¤: {result['total_count']}ê±´")
        print(f"- ê°ì„± ë¶„ì„: {result['sentiment_summary']}")
        print(f"- ì£¼ìš” í…Œë§ˆ: {result['key_themes']}")