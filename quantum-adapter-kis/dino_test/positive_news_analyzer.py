#!/usr/bin/env python3
"""
D008: í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ê¸°

ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš©ì„ AIë¡œ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ë‰´ìŠ¤ì˜ ì§‘ì¤‘ë„ì™€ ë„ë°°ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤.
- í˜¸ì¬ë‰´ìŠ¤ê°€ ì§‘ì¤‘ì ìœ¼ë¡œ ìŸì•„ì§€ëŠ” ê²½ìš° (ë„ë°°): +1ì 
- ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë¶„í¬: 0ì 
- ì•…ì¬ê°€ ë” ë§ì€ ê²½ìš°: -1ì  (í•˜ì§€ë§Œ ì´ëŠ” D007ì—ì„œ ì²˜ë¦¬)

ë„ë°° íŒë‹¨ ê¸°ì¤€:
1. í˜¸ì¬ ë‰´ìŠ¤ ë¹„ìœ¨ > 70%
2. í˜¸ì¬ ë‰´ìŠ¤ ê°œìˆ˜ â‰¥ 5ê°œ
3. ë‰´ìŠ¤ ì œëª©ì˜ ê³¼ì¥ì„± í‘œí˜„ ë¹ˆë„
"""

import logging
import requests
import os
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from .ai_client import get_ai_client

logger = logging.getLogger(__name__)

@dataclass
class PositiveNewsAnalysisResult:
    """í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ ê²°ê³¼"""
    company_name: str
    stock_code: str
    total_news_count: int           # ì „ì²´ ë‰´ìŠ¤ ìˆ˜
    positive_news_count: int        # í˜¸ì¬ ë‰´ìŠ¤ ìˆ˜
    positive_ratio: float           # í˜¸ì¬ ë‰´ìŠ¤ ë¹„ìœ¨ (0.0-1.0)
    hype_score: float              # ê³¼ì¥ì„± ì ìˆ˜ (0.0-1.0)
    flooding_score: int            # ë„ë°° ì ìˆ˜ (-1, 0, 1)
    positive_keywords_found: List[str]  # ë°œê²¬ëœ í˜¸ì¬ í‚¤ì›Œë“œë“¤
    hype_expressions: List[str]    # ê³¼ì¥ í‘œí˜„ë“¤
    analysis_summary: str          # ë¶„ì„ ìš”ì•½

class PositiveNewsAnalyzer:
    """í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ê¸°"""
    
    def __init__(self, external_api_base_url: str = "http://external-api.quantum-trading.com:8001"):
        self.base_url = external_api_base_url
        self.logger = logging.getLogger(__name__)
        
        # í†µí•© AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.ai_client = get_ai_client()
        self.ai_available = self.ai_client.is_available()
        
        if self.ai_available:
            providers = self.ai_client.get_available_providers()
            self.logger.info(f"âœ… AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {', '.join(providers)}")
        else:
            self.logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI APIê°€ ì—†ì–´ì„œ í‚¤ì›Œë“œ ë¶„ì„ë§Œ ì‚¬ìš©")
        
        # í˜¸ì¬ì„± í‚¤ì›Œë“œ ì •ì˜ (ê¸°ì¡´ news_analyzer.pyì˜ positive_keywords í™•ì¥)
        self.positive_keywords = [
            # ê¸°ë³¸ í˜¸ì¬
            "ê³„ì•½", "ìˆ˜ì£¼", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆì‹­", "íˆ¬ì", "ì¸ìˆ˜", "í•©ë³‘", "ì¶œì‹œ", "ê°œë°œ", "í˜ì‹ ",
            "ì„±ì¥", "ì¦ê°€", "ìƒìŠ¹", "ê°œì„ ", "í‘ì", "ì´ìµ", "ë§¤ì¶œ", "í™•ëŒ€", "ì§„ì¶œ", "ì„±ê³µ",
            "ìˆ˜ìƒ", "ì¸ì¦", "ìŠ¹ì¸", "ì„ ì •", "ì±„íƒ", "ë„ì…", "ëŸ°ì¹­", "ì˜¤í”ˆ",
            
            # ê³¼ì¥ í‘œí˜„
            "ê¸‰ë“±", "í­ë“±", "ê°•ì„¸", "ìµœê³ ", "ì‚¬ìƒìµœëŒ€", "ì—­ëŒ€ê¸‰", "ê¸‰ì„±ì¥", "ëŒ€ë°•",
            "ì´ˆëŒ€í˜•", "ë©”ê°€", "ìŠˆí¼", "ìš¸íŠ¸ë¼", "ìµœê°•", "ì••ë„ì ", "ë…ë³´ì ",
            "í˜ëª…ì ", "íšê¸°ì ", "ë†€ë¼ìš´", "ì—„ì²­ë‚œ", "ëŒ€ë‹¨í•œ", "ìµœê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„",
            
            # ì‹œì¥ ê´€ë ¨
            "ë§¤ìˆ˜", "ì¶”ì²œ", "ëª©í‘œê°€", "ìƒí–¥", "ê¸ì •ì ", "í˜¸ì¡°", "ë¶€ìƒ", "ì£¼ëª©",
            "ê¸°ëŒ€", "ì „ë§", "ìœ ë§", "ì ì¬ë ¥", "ê¸°íšŒ", "ëª¨ë©˜í…€", "ì´‰ì§„", "ê°€ì†í™”"
        ]
        
        # ê³¼ì¥ì„± í‘œí˜„ íŒ¨í„´
        self.hype_patterns = [
            "ê¸‰ë“±", "í­ë“±", "ëŒ€ë°•", "ì‚¬ìƒìµœëŒ€", "ì—­ëŒ€ê¸‰", "ì´ˆëŒ€í˜•", "ë©”ê°€", "ìŠˆí¼",
            "ìµœê°•", "ì••ë„ì ", "ë…ë³´ì ", "í˜ëª…ì ", "íšê¸°ì ", "ë†€ë¼ìš´", "ì—„ì²­ë‚œ",
            "!!!", "â˜…", "â˜†", "â™¥", "â—†", "â– ", "â—", "â–²", "â†‘", "â˜"
        ]
    
    def fetch_news_data(self, company_keyword: str, count: int = 30) -> List[Dict]:
        """External APIë¡œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            url = f"{self.base_url}/news/financial/{company_keyword}"
            params = {"count": count}
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            self.logger.info(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {company_keyword} - {len(items)}ê±´")
            return items
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - {company_keyword}: {e}")
            return []
    
    def analyze_with_ai(self, news_data: List[Dict], company_name: str) -> Dict:
        """AIë¥¼ í™œìš©í•œ í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ (Claude ìš°ì„ , OpenAI í´ë°±)"""
        if not self.ai_available or not news_data:
            return self._fallback_analysis(news_data, company_name)
        
        try:
            # ë‰´ìŠ¤ ì œëª©ë“¤ì„ ì¡°í•©
            news_titles = []
            for news in news_data[:15]:  # ìµœëŒ€ 15ê°œ ë‰´ìŠ¤ ë¶„ì„
                title = news.get("title", "").replace("<b>", "").replace("</b>", "")
                description = news.get("description", "")
                news_titles.append(f"{title} - {description[:100]}")
            
            if not news_titles:
                return {"flooding_score": 0, "positive_ratio": 0.0, "analysis_summary": "ë¶„ì„í•  ë‰´ìŠ¤ ì—†ìŒ"}
            
            news_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(news_titles)])
            
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = "ë‹¹ì‹ ì€ í•œêµ­ ì¦ì‹œ ë‰´ìŠ¤ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. í˜¸ì¬ ë‰´ìŠ¤ì˜ ë„ë°°ì„±ê³¼ ê³¼ì¥ì„±ì„ ì •í™•íˆ íŒë‹¨í•©ë‹ˆë‹¤."
            
            user_prompt = f"""
ë‹¤ìŒì€ {company_name}ê³¼ ê´€ë ¨ëœ ìµœê·¼ ë‰´ìŠ¤ì…ë‹ˆë‹¤:

{news_text}

ë‰´ìŠ¤ ë¶„ì„ ê¸°ì¤€:
1. í˜¸ì¬ë‰´ìŠ¤ ë„ë°°ì„± íŒë‹¨
   - í˜¸ì¬ ë‰´ìŠ¤ ë¹„ìœ¨ì´ 70% ì´ìƒì´ê³  5ê±´ ì´ìƒì¸ ê²½ìš° "ë„ë°°"ë¡œ íŒë‹¨
   - ê³¼ì¥ëœ í‘œí˜„ì´ ë§ì´ ì‚¬ìš©ëœ ê²½ìš° ê°€ì¤‘ì¹˜ ë¶€ì—¬
   - ì œëª©ì— "ê¸‰ë“±", "ëŒ€ë°•", "ì‚¬ìƒìµœëŒ€" ë“± ê³¼ì¥ í‘œí˜„ í™•ì¸

2. ì ìˆ˜ ë¶€ì—¬ ê¸°ì¤€:
   - í˜¸ì¬ë‰´ìŠ¤ ë„ë°° (70% ì´ìƒ + 5ê±´ ì´ìƒ): +1ì 
   - ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë¶„í¬: 0ì 
   - ì•…ì¬ê°€ ë” ë§ì€ ê²½ìš°: -1ì 

3. ê³¼ì¥ì„± ë¶„ì„:
   - ì œëª©ì˜ ê°ì •ì , ê³¼ì¥ì  í‘œí˜„ ë¹ˆë„ ì¸¡ì •
   - ê°ê´€ì  ì‚¬ì‹¤ vs ì£¼ê´€ì  í‰ê°€ ë¹„ìœ¨

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "flooding_score": -1, 0, ë˜ëŠ” 1,
    "positive_news_count": í˜¸ì¬ ë‰´ìŠ¤ ê°œìˆ˜,
    "total_news_count": ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜,
    "positive_ratio": í˜¸ì¬ ë‰´ìŠ¤ ë¹„ìœ¨ (0.0-1.0),
    "hype_score": ê³¼ì¥ì„± ì ìˆ˜ (0.0-1.0),
    "positive_keywords_found": ["ë°œê²¬ëœ í˜¸ì¬ í‚¤ì›Œë“œë“¤"],
    "hype_expressions": ["ê³¼ì¥ í‘œí˜„ë“¤"],
    "analysis_summary": "ë¶„ì„ ìš”ì•½"
}}
            """
            
            # AI API í˜¸ì¶œ
            result_text = self.ai_client.analyze_text(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=800
            )
            
            if not result_text:
                self.logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í´ë°±")
                return self._fallback_analysis(news_data, company_name)
            
            # JSON íŒŒì‹±
            result = self.ai_client.parse_json_response(result_text)
            if result:
                self.logger.info(f"âœ… AI í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ì„±ê³µ: {result.get('analysis_summary', 'N/A')}")
                return result
            else:
                self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ: {result_text[:200]}...")
                return self._fallback_analysis(news_data, company_name)
                
        except Exception as e:
            self.logger.error(f"AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_analysis(news_data, company_name)
    
    def _fallback_analysis(self, news_data: List[Dict], company_name: str) -> Dict:
        """AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ì„"""
        if not news_data:
            return {
                "flooding_score": 0,
                "positive_news_count": 0,
                "total_news_count": 0,
                "positive_ratio": 0.0,
                "hype_score": 0.0,
                "positive_keywords_found": [],
                "hype_expressions": [],
                "analysis_summary": "ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŒ"
            }
        
        positive_count = 0
        total_count = len(news_data)
        found_keywords = set()
        found_hype = set()
        
        for news in news_data:
            title = news.get("title", "").replace("<b>", "").replace("</b>", "")
            description = news.get("description", "")
            full_text = f"{title} {description}"
            
            # í˜¸ì¬ í‚¤ì›Œë“œ ê²€ì‚¬
            positive_matches = 0
            for keyword in self.positive_keywords:
                if keyword in full_text:
                    positive_matches += 1
                    found_keywords.add(keyword)
            
            # ê³¼ì¥ í‘œí˜„ ê²€ì‚¬
            for pattern in self.hype_patterns:
                if pattern in full_text:
                    found_hype.add(pattern)
            
            # í˜¸ì¬ ë‰´ìŠ¤ íŒì • (í‚¤ì›Œë“œ 2ê°œ ì´ìƒ)
            if positive_matches >= 2:
                positive_count += 1
        
        # ë¹„ìœ¨ ê³„ì‚°
        positive_ratio = positive_count / total_count if total_count > 0 else 0.0
        
        # ê³¼ì¥ì„± ì ìˆ˜ (ê³¼ì¥ í‘œí˜„ ë¹ˆë„ ê¸°ë°˜)
        hype_score = min(1.0, len(found_hype) / 5.0)  # ìµœëŒ€ 5ê°œ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        
        # ë„ë°° ì ìˆ˜ íŒì •
        if positive_ratio >= 0.7 and positive_count >= 5:
            flooding_score = 1  # í˜¸ì¬ë‰´ìŠ¤ ë„ë°°
        elif positive_ratio <= 0.3 and positive_count <= 2:
            flooding_score = -1  # ì•…ì¬ ìš°ì„¸
        else:
            flooding_score = 0  # ì¤‘ë¦½
        
        return {
            "flooding_score": flooding_score,
            "positive_news_count": positive_count,
            "total_news_count": total_count,
            "positive_ratio": positive_ratio,
            "hype_score": hype_score,
            "positive_keywords_found": list(found_keywords)[:10],  # ìµœëŒ€ 10ê°œ
            "hype_expressions": list(found_hype)[:5],  # ìµœëŒ€ 5ê°œ
            "analysis_summary": f"í‚¤ì›Œë“œ ë¶„ì„: í˜¸ì¬ {positive_count}/{total_count}ê±´ ({positive_ratio:.1%})"
        }
    
    def analyze_positive_news_flooding(self, stock_code: str, company_name: str = None) -> Optional[PositiveNewsAnalysisResult]:
        """D008: í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„"""
        
        search_keyword = company_name if company_name else stock_code
        
        self.logger.info(f"=== {search_keyword} ({stock_code}) D008 í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ ì‹œì‘ ===")
        
        try:
            # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.fetch_news_data(search_keyword, count=30)
            
            if not news_data:
                self.logger.warning(f"ë¶„ì„í•  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŒ: {search_keyword}")
                return None
            
            # 2. í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ ìˆ˜í–‰
            ai_result = self.analyze_with_ai(news_data, search_keyword)
            
            # 3. ê²°ê³¼ ìƒì„±
            result = PositiveNewsAnalysisResult(
                company_name=search_keyword,
                stock_code=stock_code,
                total_news_count=ai_result.get("total_news_count", len(news_data)),
                positive_news_count=ai_result.get("positive_news_count", 0),
                positive_ratio=ai_result.get("positive_ratio", 0.0),
                hype_score=ai_result.get("hype_score", 0.0),
                flooding_score=ai_result.get("flooding_score", 0),
                positive_keywords_found=ai_result.get("positive_keywords_found", []),
                hype_expressions=ai_result.get("hype_expressions", []),
                analysis_summary=ai_result.get("analysis_summary", "")
            )
            
            self.logger.info(f"D008 í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ - {search_keyword}: "
                            f"ì ìˆ˜ {result.flooding_score}, í˜¸ì¬ë¹„ìœ¨ {result.positive_ratio:.1%}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"D008 í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨ - {stock_code}: {e}")
            return None

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    analyzer = PositiveNewsAnalyzer()
    result = analyzer.analyze_positive_news_flooding("005930", "ì‚¼ì„±ì „ì")
    
    if result:
        print(f"\nğŸ“ˆ {result.company_name} ({result.stock_code}) D008 í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼")
        print(f"ì „ì²´ ë‰´ìŠ¤: {result.total_news_count}ê±´")
        print(f"í˜¸ì¬ ë‰´ìŠ¤: {result.positive_news_count}ê±´ ({result.positive_ratio:.1%})")
        print(f"ê³¼ì¥ì„± ì ìˆ˜: {result.hype_score:.2f}")
        
        if result.flooding_score == 1:
            impact_text = "ğŸŸ¢ í˜¸ì¬ë‰´ìŠ¤ ë„ë°° (+1ì )"
        elif result.flooding_score == -1:
            impact_text = "ğŸ”´ ì•…ì¬ ìš°ì„¸ (-1ì )"
        else:
            impact_text = "âšª ì¤‘ë¦½ (0ì )"
        
        print(f"D008 ì ìˆ˜: {impact_text}")
        
        if result.positive_keywords_found:
            print(f"ë°œê²¬ëœ í˜¸ì¬ í‚¤ì›Œë“œ: {', '.join(result.positive_keywords_found[:5])}")
        
        if result.hype_expressions:
            print(f"ê³¼ì¥ í‘œí˜„: {', '.join(result.hype_expressions)}")
        
        print(f"ë¶„ì„ ìš”ì•½: {result.analysis_summary}")