#!/usr/bin/env python3
"""
D002: í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆ ë¶„ì„ê¸°

ë‰´ìŠ¤ì™€ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŠ¹ì • ì¢…ëª©ì´ í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆì— ì†í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
- í…Œë§ˆ ì§‘ì¤‘ë„ ë¶„ì„
- ê´€ë ¨ì£¼ ë™ë°˜ ì›€ì§ì„ í™•ì¸  
- ì‹œì¥ ê´€ì‹¬ë„ ì¸¡ì •
- AI ê¸°ë°˜ í…Œë§ˆ íŒë‹¨

í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆë¡œ íŒë‹¨ë˜ë©´ +1ì 
"""

import logging
import requests
import os
import re
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from .ai_client import get_ai_client

logger = logging.getLogger(__name__)

@dataclass
class ThemeAnalysisResult:
    """í…Œë§ˆ ë¶„ì„ ê²°ê³¼"""
    company_name: str
    stock_code: str
    is_leading_theme: bool          # ì£¼ë„ í…Œë§ˆ ì—¬ë¶€
    theme_score: int               # í…Œë§ˆ ì ìˆ˜ (0 ë˜ëŠ” 1)
    detected_theme: str            # ê°ì§€ëœ í…Œë§ˆëª…
    confidence_score: float        # ì‹ ë¢°ë„ (0.0-1.0)
    theme_evidence: List[str]      # í…Œë§ˆ ê·¼ê±° ëª©ë¡
    related_news_count: int        # ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜
    analysis_summary: str          # ë¶„ì„ ìš”ì•½

class ThemeAnalyzer:
    """í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, external_api_base_url: str = "http://external-api.quantum-trading.com:8001"):
        self.base_url = external_api_base_url
        self.logger = logging.getLogger(__name__)
        
        # í†µí•© AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.ai_client = get_ai_client()
        self.ai_available = self.ai_client.is_available()
        
        if self.ai_available:
            providers = self.ai_client.get_available_providers()
            self.logger.info(f"âœ… AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {', '.join(providers)}")
        else:
            self.logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI APIê°€ ì—†ì–´ì„œ í‚¤ì›Œë“œ ë¶„ì„ë§Œ ì‚¬ìš©")
        
        # ì£¼ìš” í…Œë§ˆ í‚¤ì›Œë“œ ì •ì˜ (2025ë…„ ê¸°ì¤€)
        self.theme_keywords = {
            "AI/ì¸ê³µì§€ëŠ¥": [
                "AI", "ì¸ê³µì§€ëŠ¥", "ChatGPT", "LLM", "ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹", "ìƒì„±AI", 
                "GPT", "í´ë¡œë“œ", "ë¯¸ë“œì €ë‹ˆ", "ì˜¤í”ˆAI", "êµ¬ê¸€ ë°”ë“œ", "AGI"
            ],
            "ë°˜ë„ì²´": [
                "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "Dë¨", "DRAM", "ë‚¸ë“œ", "NAND", "HBM", "ì‹œìŠ¤í…œë°˜ë„ì²´",
                "íŒŒìš´ë“œë¦¬", "ì›¨ì´í¼", "ì¹©ì…‹", "AP", "GPU", "NPU", "TSMC"
            ],
            "ë°©ì‚°": [
                "ë°©ì‚°", "êµ­ë°©", "ë¬´ê¸°", "ë¯¸ì‚¬ì¼", "ì „íˆ¬ê¸°", "KF-21", "ë°©ìœ„ì‚°ì—…", 
                "êµ°ìˆ˜", "ë ˆì´ë”", "ë“œë¡ ", "ë¬´ì¸ê¸°", "êµ­ë°©ì˜ˆì‚°", "NATO"
            ],
            "ì›ìë ¥": [
                "ì›ìë ¥", "ì›ì „", "ì†Œí˜•ëª¨ë“ˆì›ìë¡œ", "SMR", "ì›ìë¡œ", "í•µë°œì „", 
                "ìš°ë¼ëŠ„", "ì›ì „ ìˆ˜ì¶œ", "APR1400", "í•œìˆ˜ì›"
            ],
            "K-POP/ì—”í„°": [
                "K-POP", "ì¼€ì´íŒ", "BTS", "ë¸”ë™í•‘í¬", "í•˜ì´ë¸Œ", "SM", "JYP", "YG",
                "ì—”í„°í…Œì¸ë¨¼íŠ¸", "í•œë¥˜", "ì½˜í…ì¸ ", "ìŒì›", "ì•¨ë²”"
            ],
            "2ì°¨ì „ì§€": [
                "ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "ESS", "ì–‘ê·¹ì¬", "ìŒê·¹ì¬", "ë¶„ë¦¬ë§‰", "ì „í•´ì§ˆ",
                "ë¦¬íŠ¬", "ì´ì°¨ì „ì§€", "LFP", "NCM", "í…ŒìŠ¬ë¼", "BYD"
            ],
            "ë°”ì´ì˜¤/ì˜ë£Œ": [
                "ë°”ì´ì˜¤", "ì œì•½", "ì‹ ì•½", "ë°±ì‹ ", "í•­ì²´", "ìœ ì „ìì¹˜ë£Œ", "ì„¸í¬ì¹˜ë£Œ",
                "ì„ìƒì‹œí—˜", "FDA", "ì‹ì•½ì²˜", "ì½”ë¡œë‚˜", "ì¹˜ë£Œì œ"
            ],
            "ê²Œì„/ë©”íƒ€ë²„ìŠ¤": [
                "ê²Œì„", "ë©”íƒ€ë²„ìŠ¤", "VR", "AR", "ê°€ìƒí˜„ì‹¤", "ì¦ê°•í˜„ì‹¤", "NFT",
                "ë¸”ë¡ì²´ì¸", "í¬ë˜í”„í†¤", "ë„¥ìŠ¨", "ì—”ì”¨ì†Œí”„íŠ¸", "ë¯¸í˜¸ìš”"
            ],
            "ìš°ì£¼í•­ê³µ": [
                "ìš°ì£¼", "í•­ê³µ", "ìœ„ì„±", "ë°œì‚¬ì²´", "ëˆ„ë¦¬í˜¸", "í•œí™”ì‹œìŠ¤í…œ", "ìŠ¤í˜ì´ìŠ¤X",
                "ìœ„ì„±í†µì‹ ", "GPS", "ìš°ì£¼ì •ê±°ì¥"
            ],
            "ì¹œí™˜ê²½/ESG": [
                "ì¹œí™˜ê²½", "ESG", "íƒ„ì†Œì¤‘ë¦½", "ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥",
                "ìˆ˜ì†Œ", "ê·¸ë¦°ë‰´ë”œ", "RE100", "íƒ„ì†Œë°°ì¶œê¶Œ"
            ]
        }
    
    def fetch_news_data(self, company_keyword: str, count: int = 30) -> List[Dict]:
        """External APIë¡œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            url = f"{self.base_url}/news/financial/{company_keyword}"
            params = {"count": count}
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            self.logger.info(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {company_keyword} - {len(items)}ê±´")
            return items
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - {company_keyword}: {e}")
            return []
    
    def extract_theme_keywords(self, text: str) -> Dict[str, int]:
        """í…ìŠ¤íŠ¸ì—ì„œ í…Œë§ˆ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹ˆë„ ê³„ì‚°"""
        theme_counts = {}
        
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
        text_lower = text.lower()
        
        for theme_name, keywords in self.theme_keywords.items():
            count = 0
            for keyword in keywords:
                # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ë‹¨ì–´ ê²½ê³„ í™•ì¸
                pattern = rf'\b{re.escape(keyword.lower())}\b'
                matches = re.findall(pattern, text_lower)
                count += len(matches)
            
            if count > 0:
                theme_counts[theme_name] = count
        
        return theme_counts
    
    def analyze_with_ai(self, news_data: List[Dict], company_name: str) -> Dict:
        """AIë¥¼ í™œìš©í•œ í…Œë§ˆ ë¶„ì„ (Claude ìš°ì„ , OpenAI í´ë°±)"""
        if not self.ai_available or not news_data:
            return self._fallback_analysis(news_data, company_name)
        
        try:
            # ë‰´ìŠ¤ ì œëª©ë“¤ì„ ì¡°í•©
            news_titles = []
            for news in news_data[:15]:  # ìµœëŒ€ 15ê°œ ë‰´ìŠ¤ ë¶„ì„
                title = news.get("title", "").replace("<b>", "").replace("</b>", "")
                description = news.get("description", "")
                news_titles.append(f"{title} - {description[:100]}")
            
            if not news_titles:
                return {"is_leading_theme": False, "theme_score": 0, "analysis_summary": "ë¶„ì„í•  ë‰´ìŠ¤ ì—†ìŒ"}
            
            news_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(news_titles)])
            
            # í˜„ì¬ ì£¼ìš” í…Œë§ˆ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            theme_list = ", ".join(self.theme_keywords.keys())
            
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = "ë‹¹ì‹ ì€ í•œêµ­ ì¦ì‹œì˜ í…Œë§ˆì£¼ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ë„ í…Œë§ˆë¥¼ ì •í™•íˆ íŒë‹¨í•©ë‹ˆë‹¤."
            
            user_prompt = f"""
ë‹¤ìŒì€ {company_name}ê³¼ ê´€ë ¨ëœ ìµœê·¼ ë‰´ìŠ¤ì…ë‹ˆë‹¤:

{news_text}

í˜„ì¬ ì£¼ìš” í…Œë§ˆ: {theme_list}

ë¶„ì„ ê¸°ì¤€:
1. íŠ¹ì • í…Œë§ˆì— ëŒ€í•œ ë‰´ìŠ¤ ì§‘ì¤‘ë„ (3ê±´ ì´ìƒ ê´€ë ¨ ë‰´ìŠ¤)
2. í…Œë§ˆì˜ ì‹œì¥ ì£¼ë„ì„± (ì •ë¶€ ì •ì±…, ê¸€ë¡œë²Œ íŠ¸ë Œë“œ ì—°ê´€ì„±)
3. ì§€ì†ì ì¸ ê´€ì‹¬ë„ (ë‹¨ìˆœ ì¼íšŒì„±ì´ ì•„ë‹Œ ì§€ì†ì  ì´ìŠˆ)
4. ê¸°ì—…ì˜ í…Œë§ˆ ë‚´ ìœ„ìƒ (ì„ ë„ ê¸°ì—… ë˜ëŠ” í•µì‹¬ ê¸°ì—… ì—¬ë¶€)

{company_name}ì´ í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆì— ì†í•˜ëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "is_leading_theme": true ë˜ëŠ” false,
    "detected_theme": "ê°€ì¥ ì—°ê´€ì„± ë†’ì€ í…Œë§ˆëª…",
    "confidence_score": 0.0-1.0 ì‹ ë¢°ë„,
    "theme_evidence": ["ê·¼ê±°1", "ê·¼ê±°2", "ê·¼ê±°3"],
    "related_news_count": ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜,
    "analysis_summary": "ë¶„ì„ ìš”ì•½"
}}
            """
            
            # AI API í˜¸ì¶œ
            result_text = self.ai_client.analyze_text(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=800
            )
            
            if not result_text:
                self.logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í´ë°±")
                return self._fallback_analysis(news_data, company_name)
            
            # JSON íŒŒì‹±
            result = self.ai_client.parse_json_response(result_text)
            if result:
                self.logger.info(f"âœ… AI í…Œë§ˆ ë¶„ì„ ì„±ê³µ: {result.get('analysis_summary', 'N/A')}")
                return result
            else:
                self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ: {result_text[:200]}...")
                return self._fallback_analysis(news_data, company_name)
                
        except Exception as e:
            self.logger.error(f"AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_analysis(news_data, company_name)
    
    def _fallback_analysis(self, news_data: List[Dict], company_name: str) -> Dict:
        """AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ì„"""
        if not news_data:
            return {
                "is_leading_theme": False,
                "detected_theme": "",
                "confidence_score": 0.0,
                "theme_evidence": [],
                "related_news_count": 0,
                "analysis_summary": "ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŒ"
            }
        
        # ëª¨ë“  ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ê²°í•©
        all_text = ""
        for news in news_data:
            title = news.get("title", "").replace("<b>", "").replace("</b>", "")
            description = news.get("description", "")
            all_text += f"{title} {description} "
        
        # í…Œë§ˆë³„ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        theme_scores = self.extract_theme_keywords(all_text)
        
        if not theme_scores:
            return {
                "is_leading_theme": False,
                "detected_theme": "",
                "confidence_score": 0.0,
                "theme_evidence": [],
                "related_news_count": 0,
                "analysis_summary": "ê´€ë ¨ í…Œë§ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            }
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í…Œë§ˆ ì„ íƒ
        top_theme = max(theme_scores, key=theme_scores.get)
        top_score = theme_scores[top_theme]
        
        # ì£¼ë„ í…Œë§ˆ íŒì • ê¸°ì¤€: í‚¤ì›Œë“œ 3íšŒ ì´ìƒ + ë‰´ìŠ¤ 5ê±´ ì´ìƒ
        is_leading = top_score >= 3 and len(news_data) >= 5
        confidence = min(0.9, (top_score / 10) + (len(news_data) / 20))
        
        evidence = [
            f"{top_theme} í‚¤ì›Œë“œ {top_score}íšŒ ì–¸ê¸‰",
            f"ê´€ë ¨ ë‰´ìŠ¤ {len(news_data)}ê±´ í™•ì¸",
            f"ì‹ ë¢°ë„ {confidence:.1%}"
        ]
        
        return {
            "is_leading_theme": is_leading,
            "detected_theme": top_theme,
            "confidence_score": confidence,
            "theme_evidence": evidence,
            "related_news_count": len(news_data),
            "analysis_summary": f"í‚¤ì›Œë“œ ë¶„ì„: {top_theme} í…Œë§ˆ {top_score}íšŒ ê°ì§€"
        }
    
    def analyze_leading_theme(self, stock_code: str, company_name: str = None) -> Optional[ThemeAnalysisResult]:
        """D002: í™•ì‹¤í•œ ì£¼ë„ í…Œë§ˆ ë¶„ì„"""
        
        search_keyword = company_name if company_name else stock_code
        
        self.logger.info(f"=== {search_keyword} ({stock_code}) D002 ì£¼ë„ í…Œë§ˆ ë¶„ì„ ì‹œì‘ ===")
        
        try:
            # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.fetch_news_data(search_keyword, count=30)
            
            if not news_data:
                self.logger.warning(f"ë¶„ì„í•  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŒ: {search_keyword}")
                return None
            
            # 2. í…Œë§ˆ ë¶„ì„ ìˆ˜í–‰
            ai_result = self.analyze_with_ai(news_data, search_keyword)
            
            # 3. ê²°ê³¼ ìƒì„±
            theme_score = 1 if ai_result.get("is_leading_theme", False) else 0
            
            result = ThemeAnalysisResult(
                company_name=search_keyword,
                stock_code=stock_code,
                is_leading_theme=ai_result.get("is_leading_theme", False),
                theme_score=theme_score,
                detected_theme=ai_result.get("detected_theme", ""),
                confidence_score=ai_result.get("confidence_score", 0.0),
                theme_evidence=ai_result.get("theme_evidence", []),
                related_news_count=ai_result.get("related_news_count", len(news_data)),
                analysis_summary=ai_result.get("analysis_summary", "")
            )
            
            self.logger.info(f"D002 í…Œë§ˆ ë¶„ì„ ì™„ë£Œ - {search_keyword}: "
                            f"ì ìˆ˜ {result.theme_score}, í…Œë§ˆ: {result.detected_theme}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"D002 í…Œë§ˆ ë¶„ì„ ì‹¤íŒ¨ - {stock_code}: {e}")
            return None

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    analyzer = ThemeAnalyzer()
    result = analyzer.analyze_leading_theme("005930", "ì‚¼ì„±ì „ì")
    
    if result:
        print(f"\nğŸ¯ {result.company_name} ({result.stock_code}) D002 í…Œë§ˆ ë¶„ì„ ê²°ê³¼")
        print(f"ì£¼ë„ í…Œë§ˆ ì—¬ë¶€: {'âœ… YES' if result.is_leading_theme else 'âŒ NO'}")
        print(f"D002 ì ìˆ˜: {result.theme_score}ì ")
        print(f"ê°ì§€ëœ í…Œë§ˆ: {result.detected_theme}")
        print(f"ì‹ ë¢°ë„: {result.confidence_score:.1%}")
        print(f"ê´€ë ¨ ë‰´ìŠ¤: {result.related_news_count}ê±´")
        
        if result.theme_evidence:
            print(f"\ní…Œë§ˆ ê·¼ê±°:")
            for i, evidence in enumerate(result.theme_evidence, 1):
                print(f"{i}. {evidence}")
        
        print(f"\në¶„ì„ ìš”ì•½: {result.analysis_summary}")