#!/usr/bin/env python3
"""
AI ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ê¸°

ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš©ì„ AIë¡œ ë¶„ì„í•˜ì—¬ ì•…ì¬/í˜¸ì¬ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
- ì•…ì¬ë‰´ìŠ¤ (ëŒ€í˜• í´ë ˆì„, ê³„ì•½ì·¨ì†Œ, ë¦¬ì½œ ë“±): -1ì 
- ì¤‘ë¦½ë‰´ìŠ¤: 0ì   
- í˜¸ì¬ë‰´ìŠ¤ (ëŒ€í˜• ê³„ì•½, ì‹ ì œí’ˆ ì¶œì‹œ, ì‹¤ì  ê°œì„  ë“±): +1ì 
"""

import logging
import requests
import os
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from .ai_client import get_ai_client

logger = logging.getLogger(__name__)

@dataclass
class NewsAnalysisResult:
    """ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼"""
    company_name: str
    stock_code: str
    total_news_count: int
    positive_news_count: int  # í˜¸ì¬ ë‰´ìŠ¤ ìˆ˜
    negative_news_count: int  # ì•…ì¬ ë‰´ìŠ¤ ìˆ˜  
    neutral_news_count: int   # ì¤‘ë¦½ ë‰´ìŠ¤ ìˆ˜
    sentiment_score: float    # ê°ì • ì ìˆ˜ (-1.0 ~ +1.0)
    material_impact: int      # ì¬ë£Œ ì˜í–¥ë„ ì ìˆ˜ (-1, 0, +1)
    key_topics: List[str]     # ì£¼ìš” í† í”½ë“¤
    analysis_summary: str     # ë¶„ì„ ìš”ì•½

class NewsAnalyzer:
    """AI ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self, external_api_base_url: str = "http://external-api.quantum-trading.com:8001"):
        self.base_url = external_api_base_url
        self.logger = logging.getLogger(__name__)
        
        # í†µí•© AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.ai_client = get_ai_client()
        self.ai_available = self.ai_client.is_available()
        
        if self.ai_available:
            providers = self.ai_client.get_available_providers()
            self.logger.info(f"âœ… AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {', '.join(providers)}")
        else:
            self.logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI APIê°€ ì—†ì–´ì„œ í‚¤ì›Œë“œ ë¶„ì„ë§Œ ì‚¬ìš©")
        
        # ì•…ì¬/í˜¸ì¬ í‚¤ì›Œë“œ ì‚¬ì „
        self.negative_keywords = [
            "í´ë ˆì„", "ë¦¬ì½œ", "ê²°í•¨", "ì¤‘ë‹¨", "ì·¨ì†Œ", "ì†Œì†¡", "ë¶„ìŸ", "ì¡°ì‚¬", "ì œì¬", "ê·œì œ",
            "ì†ì‹¤", "ì ì", "í•˜ë½", "ê°ì†Œ", "ì•…í™”", "ìœ„í—˜", "ë¬¸ì œ", "ì‚¬ê³ ", "íŒŒì—…", "ë…¸ì¡°",
            "ë¶€ì±„", "ì±„ë¬´ë¶ˆì´í–‰", "íŒŒì‚°", "íì—…", "ì² ìˆ˜", "ì¤‘ë‹¨", "ì§€ì—°", "ì‹¤íŒ¨"
        ]
        
        self.positive_keywords = [
            "ê³„ì•½", "ìˆ˜ì£¼", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆì‹­", "íˆ¬ì", "ì¸ìˆ˜", "í•©ë³‘", "ì¶œì‹œ", "ê°œë°œ", "í˜ì‹ ",
            "ì„±ì¥", "ì¦ê°€", "ìƒìŠ¹", "ê°œì„ ", "í‘ì", "ì´ìµ", "ë§¤ì¶œ", "í™•ëŒ€", "ì§„ì¶œ", "ì„±ê³µ",
            "ìˆ˜ìƒ", "ì¸ì¦", "ìŠ¹ì¸", "ì„ ì •", "ì±„íƒ", "ë„ì…", "ëŸ°ì¹­", "ì˜¤í”ˆ"
        ]
    
    def fetch_news_data(self, company_keyword: str, count: int = 20) -> Optional[List[Dict]]:
        """External APIë¡œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            url = f"{self.base_url}/news/financial/{company_keyword}"
            params = {"count": count}
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            self.logger.info(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {company_keyword} - {len(items)}ê±´")
            return items
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - {company_keyword}: {e}")
            return None
    
    def analyze_with_ai(self, news_list: List[Dict]) -> Dict:
        """AIë¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ê°ì • ë¶„ì„ (Claude ìš°ì„ , OpenAI í´ë°±)"""
        if not self.ai_available or not news_list:
            return {"sentiment_score": 0.0, "material_impact": 0, "analysis_summary": "AI ë¶„ì„ ë¶ˆê°€"}
        
        try:
            # ë‰´ìŠ¤ ì œëª©ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ì¡°í•©
            news_titles = []
            for news in news_list[:10]:  # ìµœëŒ€ 10ê°œë§Œ ë¶„ì„ (í† í° ì ˆì•½)
                title = news.get("title", "").replace("<b>", "").replace("</b>", "")
                news_titles.append(title)
            
            news_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(news_titles)])
            
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = "ë‹¹ì‹ ì€ í•œêµ­ ì¦ì‹œ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì ê´€ì ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤."
            
            user_prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ê¸°ì—…ì— ëŒ€í•œ íˆ¬ì ê´€ì ì—ì„œ í‰ê°€í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©ë“¤:
{news_text}

ë¶„ì„ ê¸°ì¤€:
1. ì•…ì¬ë‰´ìŠ¤: ëŒ€í˜• í´ë ˆì„, ê³„ì•½ì·¨ì†Œ, ë¦¬ì½œ, ì†ì‹¤, ì†Œì†¡, ê·œì œ ë“± (-1ì )
2. ì¤‘ë¦½ë‰´ìŠ¤: ì¼ë°˜ì ì¸ ì‹œì¥ ìƒí™©, ë‹¨ìˆœ ë³´ê³  ë“± (0ì )  
3. í˜¸ì¬ë‰´ìŠ¤: ëŒ€í˜• ê³„ì•½, ì‹ ì œí’ˆ ì¶œì‹œ, ì‹¤ì  ê°œì„ , íŒŒíŠ¸ë„ˆì‹­ ë“± (+1ì )

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "sentiment_score": -1.0~1.0 ì‚¬ì´ì˜ ê°ì • ì ìˆ˜,
    "material_impact": -1, 0, 1 ì¤‘ í•˜ë‚˜ì˜ ì¬ë£Œ ì˜í–¥ë„,
    "positive_count": í˜¸ì¬ ë‰´ìŠ¤ ê°œìˆ˜,
    "negative_count": ì•…ì¬ ë‰´ìŠ¤ ê°œìˆ˜,
    "neutral_count": ì¤‘ë¦½ ë‰´ìŠ¤ ê°œìˆ˜,
    "key_topics": ["ì£¼ìš” í† í”½1", "ì£¼ìš” í† í”½2"],
    "analysis_summary": "100ì ì´ë‚´ ë¶„ì„ ìš”ì•½"
}}
            """
            
            # AI API í˜¸ì¶œ
            result_text = self.ai_client.analyze_text(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=500
            )
            
            if not result_text:
                self.logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í´ë°±")
                return self._fallback_analysis(news_list)
            
            # JSON íŒŒì‹± ì‹œë„
            result = self.ai_client.parse_json_response(result_text)
            if result:
                self.logger.info(f"âœ… AI ë‰´ìŠ¤ ë¶„ì„ ì„±ê³µ: {result.get('analysis_summary', 'N/A')}")
                return result
            else:
                self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ: {result_text[:200]}...")
                return self._fallback_analysis(news_list)
                
        except Exception as e:
            self.logger.error(f"AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_analysis(news_list)
    
    def _fallback_analysis(self, news_list: List[Dict]) -> Dict:
        """AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ì„ (ê°œì„ ë¨)"""
        if not news_list:
            return {"sentiment_score": 0.0, "material_impact": 0, "positive_count": 0, 
                   "negative_count": 0, "neutral_count": 0, "key_topics": [], 
                   "analysis_summary": "ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŒ"}
        
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        topics = set()
        
        # ê°ì • ë¶„ì„ëœ ë‰´ìŠ¤ë“¤ (ë””ë²„ê¹…ìš©)
        analyzed_news = []
        
        for news in news_list:
            title = news.get("title", "").replace("<b>", "").replace("</b>", "")
            description = news.get("description", "")
            full_text = f"{title} {description}"
            
            # ëŒ€ì†Œë¬¸ì ë¬´ê´€ í‚¤ì›Œë“œ ë§¤ì¹­
            pos_matches = sum(1 for kw in self.positive_keywords if kw in full_text)
            neg_matches = sum(1 for kw in self.negative_keywords if kw in full_text)
            
            # ì¶”ê°€ì ì¸ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
            # ì£¼ê°€ ìƒìŠ¹/í•˜ë½ ê´€ë ¨
            if any(word in full_text for word in ["ìƒìŠ¹", "ì˜¤ë¦„", "ê¸‰ë“±", "ê°•ì„¸", "ë›°", "+", "ìµœê³ "]):
                pos_matches += 1
            if any(word in full_text for word in ["í•˜ë½", "ë–¨ì–´", "ê¸‰ë½", "ì•½ì„¸", "-", "ìµœì €"]):
                neg_matches += 1
            
            # ì‹¤ì  ê´€ë ¨  
            if any(word in full_text for word in ["ë§¤ì¶œ ì¦ê°€", "ì´ìµ ì¦ê°€", "ì‹¤ì  ê°œì„ ", "í‘ì"]):
                pos_matches += 2  # ê°€ì¤‘ì¹˜
            if any(word in full_text for word in ["ë§¤ì¶œ ê°ì†Œ", "ì†ì‹¤", "ì ì", "ì‹¤ì  ì•…í™”"]):
                neg_matches += 2  # ê°€ì¤‘ì¹˜
            
            # ë¶„ë¥˜ ê²°ì •
            sentiment = "ì¤‘ë¦½"
            if neg_matches > pos_matches and neg_matches > 0:
                negative_count += 1
                sentiment = "ì•…ì¬"
            elif pos_matches > neg_matches and pos_matches > 0:
                positive_count += 1
                sentiment = "í˜¸ì¬"
            else:
                neutral_count += 1
            
            analyzed_news.append({
                "title": title[:50] + "..." if len(title) > 50 else title,
                "sentiment": sentiment,
                "pos_score": pos_matches,
                "neg_score": neg_matches
            })
            
            # í† í”½ ì¶”ì¶œ (ë” ì •í™•í•˜ê²Œ)
            if any(word in full_text for word in ["ì£¼ê°€", "ì£¼ì‹", "ì‹œì„¸", "ê±°ë˜"]):
                topics.add("ì£¼ê°€ë™í–¥")
            if any(word in full_text for word in ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ì¹©", "HBM"]):
                topics.add("ë°˜ë„ì²´")  
            if any(word in full_text for word in ["AI", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹"]):
                topics.add("AI/ì¸ê³µì§€ëŠ¥")
            if any(word in full_text for word in ["ê³„ì•½", "ìˆ˜ì£¼", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆì‹­"]):
                topics.add("ê³„ì•½/í˜‘ë ¥")
            if any(word in full_text for word in ["ì‹ ì œí’ˆ", "ì¶œì‹œ", "ëŸ°ì¹­", "ê°œë°œ"]):
                topics.add("ì‹ ì œí’ˆ")
            if any(word in full_text for word in ["ì‹¤ì ", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ë¶„ê¸°"]):
                topics.add("ì‹¤ì /ì¬ë¬´")
            if any(word in full_text for word in ["ê²½ìŸ", "ë¼ì´ë²Œ", "ì‹œì¥ì ìœ ìœ¨"]):
                topics.add("ê²½ìŸë™í–¥")
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        total = positive_count + negative_count + neutral_count
        if total > 0:
            sentiment_score = (positive_count - negative_count) / total
        else:
            sentiment_score = 0.0
        
        # ì¬ë£Œ ì˜í–¥ë„ íŒì •
        if negative_count >= 3:  # ì•…ì¬ ë‰´ìŠ¤ 3ê±´ ì´ìƒ
            material_impact = -1
        elif positive_count >= 3:  # í˜¸ì¬ ë‰´ìŠ¤ 3ê±´ ì´ìƒ
            material_impact = 1
        else:
            material_impact = 0
        
        return {
            "sentiment_score": sentiment_score,
            "material_impact": material_impact,
            "positive_count": positive_count,
            "negative_count": negative_count,
            "neutral_count": neutral_count,
            "key_topics": list(topics)[:5],  # ìµœëŒ€ 5ê°œ
            "analysis_summary": f"í‚¤ì›Œë“œ ë¶„ì„: í˜¸ì¬ {positive_count}ê±´, ì•…ì¬ {negative_count}ê±´"
        }
    
    def analyze_news_sentiment(self, stock_code: str, company_name: str = None) -> Optional[NewsAnalysisResult]:
        """ì¢…ëª©ì˜ ë‰´ìŠ¤ ê°ì • ë¶„ì„"""
        
        # ê¸°ì—…ëª…ì´ ì—†ìœ¼ë©´ ì¢…ëª©ì½”ë“œë¡œ ê²€ìƒ‰
        search_keyword = company_name if company_name else stock_code
        
        self.logger.info(f"=== {search_keyword} ({stock_code}) ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œì‘ ===")
        
        try:
            # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.fetch_news_data(search_keyword, count=20)
            if not news_data:
                self.logger.warning(f"ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŒ: {search_keyword}")
                return None
            
            # 2. AI ë¶„ì„ ìˆ˜í–‰
            ai_result = self.analyze_with_ai(news_data)
            
            # 3. ë¶„ì„ ê²°ê³¼ ìƒì„±
            result = NewsAnalysisResult(
                company_name=search_keyword,
                stock_code=stock_code,
                total_news_count=len(news_data),
                positive_news_count=ai_result.get("positive_count", 0),
                negative_news_count=ai_result.get("negative_count", 0),
                neutral_news_count=ai_result.get("neutral_count", 0),
                sentiment_score=ai_result.get("sentiment_score", 0.0),
                material_impact=ai_result.get("material_impact", 0),
                key_topics=ai_result.get("key_topics", []),
                analysis_summary=ai_result.get("analysis_summary", "")
            )
            
            self.logger.info(f"ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ - {search_keyword}: "
                            f"ê°ì •ì ìˆ˜ {result.sentiment_score:.2f}, ì¬ë£Œì˜í–¥ {result.material_impact}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤íŒ¨ - {stock_code}: {e}")
            return None

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    analyzer = NewsAnalyzer()
    result = analyzer.analyze_news_sentiment("005930", "ì‚¼ì„±ì „ì")
    
    if result:
        print(f"\nğŸ“° {result.company_name} ({result.stock_code}) ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼")
        print(f"ì „ì²´ ë‰´ìŠ¤: {result.total_news_count}ê±´")
        print(f"í˜¸ì¬: {result.positive_news_count}ê±´ | ì•…ì¬: {result.negative_news_count}ê±´ | ì¤‘ë¦½: {result.neutral_news_count}ê±´")
        print(f"ê°ì • ì ìˆ˜: {result.sentiment_score:.3f} (-1.0 ~ +1.0)")
        
        if result.material_impact == 1:
            impact_text = "ğŸŸ¢ í˜¸ì¬ (+1ì )"
        elif result.material_impact == -1:
            impact_text = "ğŸ”´ ì•…ì¬ (-1ì )"
        else:
            impact_text = "âšª ì¤‘ë¦½ (0ì )"
        
        print(f"ì¬ë£Œ ì˜í–¥ë„: {impact_text}")
        
        if result.key_topics:
            print(f"ì£¼ìš” í† í”½: {', '.join(result.key_topics)}")
        
        print(f"ë¶„ì„ ìš”ì•½: {result.analysis_summary}")