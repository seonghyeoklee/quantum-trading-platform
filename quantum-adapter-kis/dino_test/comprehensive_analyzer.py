#!/usr/bin/env python3
"""
ì¢…í•© DINO í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì €ì¥ ì‹œìŠ¤í…œ

ëª¨ë“  DINO ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ì™€ Raw ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
- 9ê°œ ë¶„ì„ ì˜ì—­ ì‹¤í–‰
- ëª¨ë“  Raw ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
- í•˜ë£¨ 1íšŒ ë¶„ì„ ì œí•œ (unique constraint)
- AI ì‘ë‹µ ë° í™˜ê²½ ì •ë³´ ë³´ì¡´
"""

import logging
import psycopg2
import json
from datetime import datetime, date
from typing import Optional, Dict, List, Any
from dataclasses import dataclass, asdict

from .finance_data_collector import FinanceDataCollector
from .finance_scorer import DinoTestFinanceScorer
from .theme_analyzer import ThemeAnalyzer
from .material_analyzer import DinoTestMaterialAnalyzer
from .interest_coverage_analyzer import InterestCoverageAnalyzer
from .news_analyzer import NewsAnalyzer
from .event_analyzer import EventAnalyzer
from .positive_news_analyzer import PositiveNewsAnalyzer
from .technical_analyzer import DinoTestTechnicalAnalyzer
from .price_analyzer import DinoTestPriceAnalyzer

logger = logging.getLogger(__name__)

@dataclass
class ComprehensiveDinoResult:
    """ì¢…í•© DINO í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    stock_code: str
    company_name: str
    user_id: int
    
    # 9ê°œ ë¶„ì„ ì˜ì—­ ì ìˆ˜
    finance_score: int = 0           # D001: ì¬ë¬´ ë¶„ì„ (0-5)
    technical_score: int = 0         # ê¸°ìˆ ì  ë¶„ì„ (0-5) - TODO
    price_score: int = 0            # ê°€ê²© ë¶„ì„ (0-5) - TODO
    material_score: int = 0         # D003: ì†Œì¬ ë¶„ì„ (0-5)
    event_score: int = 0            # D001: ì´ë²¤íŠ¸ ë¶„ì„ (0 or 1)
    theme_score: int = 0            # D002: í…Œë§ˆ ë¶„ì„ (0 or 1)
    positive_news_score: int = 0    # D008: í˜¸ì¬ë‰´ìŠ¤ ë„ë°° (-1, 0, 1)
    interest_coverage_score: int = 0 # D009: ì´ìë³´ìƒë°°ìœ¨ (0-5)
    
    analysis_date: date = None
    status: str = "PENDING"
    
    def __post_init__(self):
        if self.analysis_date is None:
            self.analysis_date = date.today()
    
    @property
    def total_score(self) -> int:
        """ì´ ì ìˆ˜ ê³„ì‚°"""
        return (self.finance_score + self.technical_score + self.price_score + 
                self.material_score + self.event_score + self.theme_score + 
                self.positive_news_score + self.interest_coverage_score)

@dataclass
class RawDataCollection:
    """Raw ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼"""
    # ì™¸ë¶€ API Raw ë°ì´í„°
    news_raw_data: Optional[Dict] = None
    disclosure_raw_data: Optional[Dict] = None
    financial_raw_data: Optional[Dict] = None
    technical_raw_data: Optional[Dict] = None
    price_raw_data: Optional[Dict] = None
    material_raw_data: Optional[Dict] = None
    
    # AI ë¶„ì„ ì‘ë‹µ ì›ë¬¸
    ai_theme_response: Optional[str] = None
    ai_news_response: Optional[str] = None
    ai_event_response: Optional[str] = None
    ai_positive_news_response: Optional[str] = None
    
    # ë¶„ì„ í™˜ê²½ ì •ë³´
    analysis_environment: Optional[Dict] = None
    ai_model_info: Optional[Dict] = None

class ComprehensiveDinoAnalyzer:
    """ì¢…í•© DINO í…ŒìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self, db_host: str = "localhost", db_port: int = 5432, 
                 db_name: str = "quantum_trading", db_user: str = "quantum", 
                 db_password: str = "quantum123"):
        self.logger = logging.getLogger(__name__)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        self.db_config = {
            "host": db_host,
            "port": db_port,
            "database": db_name,
            "user": db_user,
            "password": db_password
        }
        
        # ê°œë³„ ë¶„ì„ê¸° ì´ˆê¸°í™” (í•„ìš”í•  ë•Œ ë™ì  ë¡œë“œ)
        self.finance_data_collector = None
        self.finance_scorer = None
        
        self.logger.info("âœ… ComprehensiveDinoAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def check_existing_analysis(self, stock_code: str, analysis_date: date = None) -> bool:
        """ê¸°ì¡´ ë¶„ì„ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (í•˜ë£¨ 1íšŒ ì œí•œ)"""
        if analysis_date is None:
            analysis_date = date.today()
        
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT COUNT(*) FROM dino_test_results 
                        WHERE stock_code = %s AND analysis_date = %s
                    """, (stock_code, analysis_date))
                    
                    count = cursor.fetchone()[0]
                    exists = count > 0
                    
                    if exists:
                        self.logger.warning(f"âš ï¸ {stock_code} ì˜¤ëŠ˜ ë¶„ì„ ì´ë¯¸ ì¡´ì¬: {analysis_date}")
                    
                    return exists
                    
        except Exception as e:
            self.logger.error(f"ê¸°ì¡´ ë¶„ì„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def run_comprehensive_analysis(self, stock_code: str, company_name: str = None, 
                                 user_id: int = 1, force_rerun: bool = False) -> Optional[ComprehensiveDinoResult]:
        """ì¢…í•© DINO ë¶„ì„ ì‹¤í–‰"""
        
        search_name = company_name if company_name else stock_code
        self.logger.info(f"ğŸš€ ì¢…í•© DINO ë¶„ì„ ì‹œì‘: {search_name} ({stock_code})")
        
        # 1. ê¸°ì¡´ ë¶„ì„ í™•ì¸ (ê°•ì œ ì¬ì‹¤í–‰ì´ ì•„ë‹Œ ê²½ìš°)
        if not force_rerun and self.check_existing_analysis(stock_code):
            self.logger.info(f"â­ï¸ ì˜¤ëŠ˜ ì´ë¯¸ ë¶„ì„ë¨, ê±´ë„ˆëœ€: {stock_code}")
            return None
        
        # 2. ê²°ê³¼ ë° Raw ë°ì´í„° ê°ì²´ ì´ˆê¸°í™”
        result = ComprehensiveDinoResult(
            stock_code=stock_code,
            company_name=search_name,
            user_id=user_id,
            status="RUNNING"
        )
        
        raw_data = RawDataCollection()
        
        # 3. ë¶„ì„ í™˜ê²½ ì •ë³´ ìˆ˜ì§‘
        raw_data.analysis_environment = {
            "analysis_timestamp": datetime.now().isoformat(),
            "python_version": "3.13",
            "system": "quantum-adapter-kis",
            "analyzer_version": "1.0.0"
        }
        
        try:
            # ì‹¤ì œ ë¶„ì„ê¸°ë“¤ì„ ì‚¬ìš©í•œ ì¢…í•© ë¶„ì„
            
            # 4. D002: í…Œë§ˆ ë¶„ì„ (AI ê¸°ë°˜)
            self.logger.info("ğŸ¯ D002 í…Œë§ˆ ë¶„ì„ ì‹¤í–‰ì¤‘...")
            try:
                theme_analyzer = ThemeAnalyzer()
                theme_result = theme_analyzer.analyze_leading_theme(stock_code, search_name)
                if theme_result:
                    result.theme_score = theme_result.theme_score
                    raw_data.ai_theme_response = theme_result.analysis_summary
                    
                    # í…Œë§ˆ ë¶„ì„ì— ì‚¬ìš©ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
                    theme_news_data = theme_analyzer.fetch_news_data(search_name, count=30)
                    news_links = []
                    for news in theme_news_data[:10]:  # ìƒìœ„ 10ê°œ ë‰´ìŠ¤ ë§í¬ë§Œ ì €ì¥
                        if news.get('link'):
                            news_links.append({
                                'title': news.get('title', '').replace('<b>', '').replace('</b>', ''),
                                'link': news.get('link'),
                                'pub_date': news.get('pubDate', ''),
                                'description': news.get('description', '')[:100] + '...' if news.get('description') else ''
                            })
                    
                    raw_data.news_raw_data = {
                        "theme_analysis": {
                            "detected_theme": theme_result.detected_theme,
                            "confidence_score": theme_result.confidence_score,
                            "is_leading_theme": theme_result.is_leading_theme,
                            "related_news_count": theme_result.related_news_count,
                            "analyzed_news_links": news_links
                        }
                    }
                    self.logger.info(f"âœ… D002 í…Œë§ˆ ë¶„ì„ ì™„ë£Œ: {result.theme_score}ì , í…Œë§ˆ: {theme_result.detected_theme}, ë‰´ìŠ¤ {len(news_links)}ê±´ ë§í¬ ì €ì¥")
            except Exception as e:
                self.logger.warning(f"âš ï¸ D002 í…Œë§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
                result.theme_score = 0
            
            # 5. D009: ì´ìë³´ìƒë°°ìœ¨ ë¶„ì„
            self.logger.info("ğŸ¦ D009 ì´ìë³´ìƒë°°ìœ¨ ë¶„ì„ ì‹¤í–‰ì¤‘...")
            try:
                coverage_analyzer = InterestCoverageAnalyzer()
                coverage_result = coverage_analyzer.analyze_interest_coverage(stock_code, search_name)
                if coverage_result:
                    result.interest_coverage_score = coverage_result.coverage_score
                    raw_data.financial_raw_data = raw_data.financial_raw_data or {}
                    raw_data.financial_raw_data.update({
                        "interest_coverage": {
                            "coverage_ratio": coverage_result.interest_coverage_ratio,
                            "ebit": coverage_result.ebit,
                            "interest_expense": coverage_result.interest_expense,
                            "analysis_summary": coverage_result.analysis_summary
                        }
                    })
                    self.logger.info(f"âœ… D009 ì´ìë³´ìƒë°°ìœ¨ ë¶„ì„ ì™„ë£Œ: {result.interest_coverage_score}ì ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ D009 ì´ìë³´ìƒë°°ìœ¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
                result.interest_coverage_score = 0
            
            # 6. D001: ì´ë²¤íŠ¸ ë¶„ì„ (êµ¬ì²´ì  í˜¸ì¬ ì„ë°•)
            self.logger.info("ğŸ“… D001 ì´ë²¤íŠ¸ ë¶„ì„ ì‹¤í–‰ì¤‘...")
            try:
                event_analyzer = EventAnalyzer()
                event_result = event_analyzer.analyze_imminent_events(stock_code, search_name)
                if event_result:
                    result.event_score = event_result.event_score
                    raw_data.ai_event_response = event_result.analysis_summary
                    
                    # ì´ë²¤íŠ¸ ë¶„ì„ì— ì‚¬ìš©ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
                    event_news_data = event_analyzer.fetch_news_data(search_name, count=20)
                    event_news_links = []
                    for news in event_news_data[:10]:  # ìƒìœ„ 10ê°œ ë‰´ìŠ¤ ë§í¬ ì €ì¥
                        if news.get('link'):
                            event_news_links.append({
                                'title': news.get('title', '').replace('<b>', '').replace('</b>', ''),
                                'link': news.get('link'),
                                'pub_date': news.get('pubDate', ''),
                                'description': news.get('description', '')[:100] + '...' if news.get('description') else ''
                            })
                    
                    raw_data.disclosure_raw_data = {
                        "imminent_events": {
                            "events_count": event_result.imminent_events_count,
                            "detected_events": event_result.detected_events,
                            "total_sources": event_result.total_sources,
                            "analyzed_news_links": event_news_links
                        }
                    }
                    self.logger.info(f"âœ… D001 ì´ë²¤íŠ¸ ë¶„ì„ ì™„ë£Œ: {result.event_score}ì , ë‰´ìŠ¤ {len(event_news_links)}ê±´ ë§í¬ ì €ì¥")
            except Exception as e:
                self.logger.warning(f"âš ï¸ D001 ì´ë²¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                result.event_score = 0
            
            # 7. D008: í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„
            self.logger.info("ğŸ“ˆ D008 í˜¸ì¬ë‰´ìŠ¤ ë„ë°° ë¶„ì„ ì‹¤í–‰ì¤‘...")
            try:
                positive_analyzer = PositiveNewsAnalyzer()
                positive_result = positive_analyzer.analyze_positive_news_flooding(stock_code, search_name)
                if positive_result:
                    result.positive_news_score = positive_result.flooding_score
                    raw_data.ai_positive_news_response = positive_result.analysis_summary
                    
                    # í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ì— ì‚¬ìš©ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
                    positive_news_data = positive_analyzer.fetch_news_data(search_name, count=30)
                    positive_news_links = []
                    for news in positive_news_data[:15]:  # ìƒìœ„ 15ê°œ ë‰´ìŠ¤ ë§í¬ ì €ì¥ (í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ì€ ë” ë§ì´ ì €ì¥)
                        if news.get('link'):
                            positive_news_links.append({
                                'title': news.get('title', '').replace('<b>', '').replace('</b>', ''),
                                'link': news.get('link'),
                                'pub_date': news.get('pubDate', ''),
                                'description': news.get('description', '')[:100] + '...' if news.get('description') else ''
                            })
                    
                    raw_data.news_raw_data = raw_data.news_raw_data or {}
                    raw_data.news_raw_data.update({
                        "positive_news_analysis": {
                            "positive_ratio": positive_result.positive_ratio,
                            "hype_score": positive_result.hype_score,
                            "positive_keywords": positive_result.positive_keywords_found,
                            "hype_expressions": positive_result.hype_expressions,
                            "analyzed_news_links": positive_news_links
                        }
                    })
                    self.logger.info(f"âœ… D008 í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ: {result.positive_news_score}ì , ë‰´ìŠ¤ {len(positive_news_links)}ê±´ ë§í¬ ì €ì¥")
            except Exception as e:
                self.logger.warning(f"âš ï¸ D008 í˜¸ì¬ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
                result.positive_news_score = 0
            
            # 8. ê¸°ì¡´ DINO í…ŒìŠ¤íŠ¸ ë¶„ì„ê¸°ë“¤ í˜¸ì¶œ (ì‹¤ì œ API í˜¸ì¶œ)
            self.logger.info("ğŸ“Š ê¸°ì¡´ DINO ë¶„ì„ê¸°ë“¤ ì‹¤í–‰ì¤‘...")
            
            # D001 ì¬ë¬´ë¶„ì„ - HTTP API í˜¸ì¶œ
            try:
                import requests
                response = requests.get(f"http://localhost:8000/dino-test/finance/{stock_code}", timeout=30)
                if response.status_code == 200:
                    finance_data = response.json()
                    result.finance_score = finance_data.get('total_score', 0)
                    raw_data.financial_raw_data = raw_data.financial_raw_data or {}
                    raw_data.financial_raw_data.update({
                        "finance_analysis": finance_data.get('raw_data', {}),
                        "score_details": finance_data.get('score_details', {}),
                        "total_score": finance_data.get('total_score', 0)
                    })
                    self.logger.info(f"âœ… D001 ì¬ë¬´ ë¶„ì„ ì™„ë£Œ: {result.finance_score}ì ")
                else:
                    self.logger.warning(f"âš ï¸ D001 ì¬ë¬´ ë¶„ì„ API ì‹¤íŒ¨: {response.status_code}")
                    result.finance_score = 0
            except Exception as e:
                self.logger.warning(f"âš ï¸ D001 ì¬ë¬´ ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                result.finance_score = 0
            
            # D003 ì†Œì¬ë¶„ì„ - HTTP API í˜¸ì¶œ
            try:
                response = requests.get(f"http://localhost:8000/dino-test/material/{stock_code}", timeout=30)
                if response.status_code == 200:
                    material_data = response.json()
                    result.material_score = material_data.get('total_score', 0)
                    raw_data.material_raw_data = {
                        "material_analysis": material_data.get('raw_data', {}),
                        "score_details": material_data.get('score_details', {}),
                        "total_score": material_data.get('total_score', 0)
                    }
                    self.logger.info(f"âœ… D003 ì†Œì¬ ë¶„ì„ ì™„ë£Œ: {result.material_score}ì ")
                else:
                    self.logger.warning(f"âš ï¸ D003 ì†Œì¬ ë¶„ì„ API ì‹¤íŒ¨: {response.status_code}")
                    result.material_score = 0
            except Exception as e:
                self.logger.warning(f"âš ï¸ D003 ì†Œì¬ ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                result.material_score = 0
            
            # ê¸°ìˆ ì  ë¶„ì„ - HTTP API í˜¸ì¶œ
            try:
                response = requests.get(f"http://localhost:8000/dino-test/technical/{stock_code}", timeout=30)
                if response.status_code == 200:
                    technical_data = response.json()
                    result.technical_score = technical_data.get('total_score', 0)
                    raw_data.technical_raw_data = {
                        "technical_analysis": technical_data.get('raw_data', {}),
                        "score_details": technical_data.get('score_details', {}),
                        "total_score": technical_data.get('total_score', 0)
                    }
                    self.logger.info(f"âœ… ê¸°ìˆ ì  ë¶„ì„ ì™„ë£Œ: {result.technical_score}ì ")
                else:
                    self.logger.warning(f"âš ï¸ ê¸°ìˆ ì  ë¶„ì„ API ì‹¤íŒ¨: {response.status_code}")
                    result.technical_score = 0
            except Exception as e:
                self.logger.warning(f"âš ï¸ ê¸°ìˆ ì  ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                result.technical_score = 0
            
            # ê°€ê²© ë¶„ì„ - HTTP API í˜¸ì¶œ
            try:
                response = requests.get(f"http://localhost:8000/dino-test/price/{stock_code}", timeout=30)
                if response.status_code == 200:
                    price_data = response.json()
                    result.price_score = price_data.get('total_score', 0)
                    raw_data.price_raw_data = {
                        "price_analysis": price_data.get('raw_data', {}),
                        "score_details": price_data.get('score_details', {}),
                        "total_score": price_data.get('total_score', 0)
                    }
                    self.logger.info(f"âœ… ê°€ê²© ë¶„ì„ ì™„ë£Œ: {result.price_score}ì ")
                else:
                    self.logger.warning(f"âš ï¸ ê°€ê²© ë¶„ì„ API ì‹¤íŒ¨: {response.status_code}")
                    result.price_score = 0
            except Exception as e:
                self.logger.warning(f"âš ï¸ ê°€ê²© ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                result.price_score = 0
            
            # AI ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘ (ì‹¤ì œ í™˜ê²½ ë°˜ì˜)
            raw_data.ai_model_info = {
                "primary_provider": "anthropic_claude",
                "fallback_provider": "openai_gpt", 
                "model_versions": {
                    "claude": "haiku-3",
                    "openai": "gpt-3.5-turbo"
                },
                "real_analysis": True
            }
            
            self.logger.info(f"âœ… ì‹¤ì œ ë¶„ì„ê¸° í˜¸ì¶œ ì™„ë£Œ - ì´ì : {result.total_score}ì ")
            
            # 11. ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
            result.status = "COMPLETED"
            total = result.total_score
            
            self.logger.info(f"ğŸ‰ ì¢…í•© DINO ë¶„ì„ ì™„ë£Œ: {search_name} - ì´ì  {total}ì ")
            
            # 12. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            saved_id = self.save_to_database(result, raw_data)
            if saved_id:
                self.logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: ID {saved_id}")
                return result
            else:
                self.logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© ë¶„ì„ ì‹¤íŒ¨ - {stock_code}: {e}")
            result.status = "FAILED"
            return None
    
    def save_to_database(self, result: ComprehensiveDinoResult, raw_data: RawDataCollection) -> Optional[int]:
        """ë¶„ì„ ê²°ê³¼ì™€ Raw ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cursor:
                    # 1. DINO í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
                    cursor.execute("""
                        INSERT INTO dino_test_results (
                            stock_code, company_name, user_id,
                            finance_score, technical_score, price_score, material_score,
                            event_score, theme_score, positive_news_score, interest_coverage_score,
                            analysis_date, status
                        ) VALUES (
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                        ) RETURNING id
                    """, (
                        result.stock_code, result.company_name, result.user_id,
                        result.finance_score, result.technical_score, result.price_score, result.material_score,
                        result.event_score, result.theme_score, result.positive_news_score, result.interest_coverage_score,
                        result.analysis_date, result.status
                    ))
                    
                    dino_result_id = cursor.fetchone()[0]
                    
                    # 2. Raw ë°ì´í„° ì €ì¥
                    cursor.execute("""
                        INSERT INTO dino_test_raw_data (
                            dino_test_result_id,
                            news_raw_data, disclosure_raw_data, financial_raw_data,
                            technical_raw_data, price_raw_data, material_raw_data,
                            ai_theme_response, ai_news_response, ai_event_response, ai_positive_news_response,
                            analysis_environment, ai_model_info
                        ) VALUES (
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                        )
                    """, (
                        dino_result_id,
                        json.dumps(raw_data.news_raw_data) if raw_data.news_raw_data else None,
                        json.dumps(raw_data.disclosure_raw_data) if raw_data.disclosure_raw_data else None,
                        json.dumps(raw_data.financial_raw_data) if raw_data.financial_raw_data else None,
                        json.dumps(raw_data.technical_raw_data) if raw_data.technical_raw_data else None,
                        json.dumps(raw_data.price_raw_data) if raw_data.price_raw_data else None,
                        json.dumps(raw_data.material_raw_data) if raw_data.material_raw_data else None,
                        raw_data.ai_theme_response,
                        raw_data.ai_news_response,
                        raw_data.ai_event_response,
                        raw_data.ai_positive_news_response,
                        json.dumps(raw_data.analysis_environment) if raw_data.analysis_environment else None,
                        json.dumps(raw_data.ai_model_info) if raw_data.ai_model_info else None
                    ))
                    
                    conn.commit()
                    self.logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: dino_test_results.id = {dino_result_id}")
                    return dino_result_id
                    
        except psycopg2.IntegrityError as e:
            if "uk_dino_test_daily" in str(e):
                self.logger.warning(f"âš ï¸ ì˜¤ëŠ˜ ì´ë¯¸ ë¶„ì„ëœ ì¢…ëª©: {result.stock_code}")
                return None
            else:
                self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ì˜¤ë¥˜: {e}")
                return None
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def get_analysis_results(self, stock_code: str = None, analysis_date: date = None, 
                           limit: int = 100) -> List[Dict]:
        """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cursor:
                    query = """
                        SELECT 
                            stock_code, company_name, 
                            finance_score, technical_score, price_score, material_score,
                            event_score, theme_score, positive_news_score, interest_coverage_score,
                            total_score, analysis_grade,
                            analysis_date, created_at, status
                        FROM dino_test_results 
                        WHERE 1=1
                    """
                    params = []
                    
                    if stock_code:
                        query += " AND stock_code = %s"
                        params.append(stock_code)
                    
                    if analysis_date:
                        query += " AND analysis_date = %s"
                        params.append(analysis_date)
                    
                    query += " ORDER BY created_at DESC LIMIT %s"
                    params.append(limit)
                    
                    cursor.execute(query, params)
                    
                    columns = [desc[0] for desc in cursor.description]
                    results = []
                    
                    for row in cursor.fetchall():
                        result = dict(zip(columns, row))
                        # ë‚ ì§œ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                        if result.get('analysis_date'):
                            result['analysis_date'] = result['analysis_date'].isoformat()
                        if result.get('created_at'):
                            result['created_at'] = result['created_at'].isoformat()
                        results.append(result)
                    
                    return results
                    
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    analyzer = ComprehensiveDinoAnalyzer()
    
    # ì‚¼ì„±ì „ì ì¢…í•© ë¶„ì„ í…ŒìŠ¤íŠ¸
    result = analyzer.run_comprehensive_analysis("005930", "ì‚¼ì„±ì „ì", force_rerun=True)
    
    if result:
        print(f"\nğŸ‰ {result.company_name} ({result.stock_code}) ì¢…í•© DINO ë¶„ì„ ê²°ê³¼")
        print(f"ğŸ“Š D001 ì¬ë¬´ë¶„ì„: {result.finance_score}ì ")
        print(f"ğŸ¯ D002 í…Œë§ˆë¶„ì„: {result.theme_score}ì ")
        print(f"ğŸ’° D003 ì†Œì¬ë¶„ì„: {result.material_score}ì ")
        print(f"ğŸ“… D001 ì´ë²¤íŠ¸ë¶„ì„: {result.event_score}ì ")
        print(f"ğŸ“ˆ D008 í˜¸ì¬ë‰´ìŠ¤: {result.positive_news_score}ì ")
        print(f"ğŸ¦ D009 ì´ìë³´ìƒë°°ìœ¨: {result.interest_coverage_score}ì ")
        print(f"ğŸ† ì´ì : {result.total_score}ì ")
        print(f"ğŸ“… ë¶„ì„ì¼: {result.analysis_date}")
        print(f"âœ… ìƒíƒœ: {result.status}")
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨")