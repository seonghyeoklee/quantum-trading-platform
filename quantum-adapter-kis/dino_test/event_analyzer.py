#!/usr/bin/env python3
"""
D001: êµ¬ì²´í™”ëœ ì´ë²¤íŠ¸/í˜¸ì¬ ì„ë°• ë¶„ì„ê¸°

ë‰´ìŠ¤ì™€ ê³µì‹œì—ì„œ êµ¬ì²´ì ì¸ ë‚ ì§œê°€ ëª…ì‹œëœ í˜¸ì¬ì„± ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
- ì‹ ì œí’ˆ ì¶œì‹œ
- ì‹¤ì  ë°œí‘œ/IR
- ê³„ì•½ ì²´ê²°/íŒŒíŠ¸ë„ˆì‹­
- ìŠ¹ì¸/ì¸ì¦ ê´€ë ¨
- ê¸°íƒ€ í˜¸ì¬ì„± ì´ë²¤íŠ¸

êµ¬ì²´ì ì¸ ë‚ ì§œê°€ í¬í•¨ëœ í˜¸ì¬ ì´ë²¤íŠ¸ ë°œê²¬ ì‹œ +1ì 
"""

import logging
import requests
import openai
import os
import re
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

@dataclass
class EventAnalysisResult:
    """ì´ë²¤íŠ¸ ë¶„ì„ ê²°ê³¼"""
    company_name: str
    stock_code: str
    total_sources: int          # ë¶„ì„í•œ ë‰´ìŠ¤+ê³µì‹œ ìˆ˜
    imminent_events_count: int  # ì„ë°•í•œ í˜¸ì¬ ì´ë²¤íŠ¸ ìˆ˜
    event_score: int           # ì´ë²¤íŠ¸ ì ìˆ˜ (0 ë˜ëŠ” 1)
    detected_events: List[Dict] # ê°ì§€ëœ ì´ë²¤íŠ¸ ëª©ë¡
    analysis_summary: str      # ë¶„ì„ ìš”ì•½

@dataclass 
class DetectedEvent:
    """ê°ì§€ëœ ì´ë²¤íŠ¸"""
    event_type: str       # ì´ë²¤íŠ¸ ìœ í˜• (ì‹ ì œí’ˆ, ì‹¤ì ë°œí‘œ, ê³„ì•½, ìŠ¹ì¸ ë“±)
    description: str      # ì´ë²¤íŠ¸ ì„¤ëª…
    date_mention: str     # ë‚ ì§œ ì–¸ê¸‰ ë¶€ë¶„
    source: str          # ì¶œì²˜ (ë‰´ìŠ¤ ë˜ëŠ” ê³µì‹œ)
    title: str           # ì œëª©
    urgency_score: float # ì„ë°•ì„± ì ìˆ˜ (0-1)

class EventAnalyzer:
    """êµ¬ì²´í™”ëœ ì´ë²¤íŠ¸/í˜¸ì¬ ì„ë°• ë¶„ì„ê¸°"""
    
    def __init__(self, external_api_base_url: str = "http://external-api.quantum-trading.com:8001"):
        self.base_url = external_api_base_url
        self.logger = logging.getLogger(__name__)
        
        # OpenAI API í‚¤ ì„¤ì •
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            openai.api_key = openai_api_key
            self.openai_available = True
            self.logger.info("âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ")
        else:
            self.openai_available = False
            self.logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ì„œ AI ë¶„ì„ ë¹„í™œì„±í™”")
        
        # í˜¸ì¬ì„± ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ì •ì˜
        self.positive_event_keywords = {
            "ì‹ ì œí’ˆ_ì¶œì‹œ": ["ì¶œì‹œ", "ëŸ°ì¹­", "ë¡ ì¹­", "ê³µê°œ", "ë°œí‘œ", "ì„ ë³´", "ë°ë·”", "ì˜¤í”ˆ", "ëŸ°ì¹˜"],
            "ì‹¤ì _IR": ["ì‹¤ì ", "ì–´ë‹", "ì»¨í¼ëŸ°ìŠ¤ì½œ", "IR", "íˆ¬ìì", "ì„¤ëª…íšŒ", "ë°œí‘œíšŒ", "ë³´ê³ ì„œ"],
            "ê³„ì•½_íŒŒíŠ¸ë„ˆì‹­": ["ê³„ì•½", "ìˆ˜ì£¼", "íŒŒíŠ¸ë„ˆì‹­", "í˜‘ë ¥", "MOU", "ì–‘í•´ê°ì„œ", "ì œíœ´", "í•©ì‘"],
            "ìŠ¹ì¸_ì¸ì¦": ["ìŠ¹ì¸", "í—ˆê°€", "ì¸ì¦", "íŠ¹í—ˆ", "ë¼ì´ì„¼ìŠ¤", "ë“±ë¡", "í†µê³¼", "ì·¨ë“"],
            "íˆ¬ì_M&A": ["íˆ¬ì", "ì¸ìˆ˜", "í•©ë³‘", "ì§€ë¶„", "ì¶œì", "í€ë”©", "ìê¸ˆì¡°ë‹¬"],
            "ê¸°íƒ€_í˜¸ì¬": ["ìˆ˜ìƒ", "ì„ ì •", "ì±„íƒ", "ë„ì…", "í™•ì¥", "ì§„ì¶œ", "ì„±ì¥", "ê°œì„ "]
        }
        
        # ë‚ ì§œ íŒ¨í„´ ì •ê·œí‘œí˜„ì‹ (í•œêµ­ì–´)
        self.date_patterns = [
            r'\d{4}ë…„\s*\d{1,2}ì›”',           # 2025ë…„ 3ì›”
            r'\d{1,2}ì›”\s*\d{1,2}ì¼',         # 3ì›” 15ì¼
            r'ë‹¤ìŒ\s*(ì£¼|ë‹¬|ì›”|ë¶„ê¸°|ë…„)',      # ë‹¤ìŒ ì£¼/ë‹¬/ì›”/ë¶„ê¸°/ë…„
            r'ì´ë²ˆ\s*(ì£¼|ë‹¬|ì›”|ë¶„ê¸°|ë…„)',      # ì´ë²ˆ ì£¼/ë‹¬/ì›”/ë¶„ê¸°/ë…„
            r'ê³§|ì„ë°•|ì˜ˆì •|ê³„íš|ì¤€ë¹„',         # ê³§, ì„ë°•, ì˜ˆì •, ê³„íš
            r'\d{1,2}ì¼\s*ì˜ˆì •',             # 15ì¼ ì˜ˆì •
            r'\d{1,2}ì›”\s*ì¤‘',               # 3ì›” ì¤‘
            r'\d+ë¶„ê¸°',                      # 1ë¶„ê¸°, 2ë¶„ê¸°
            r'ì—°ë‚´|ì˜¬í•´|ë‚´ë…„',               # ì—°ë‚´, ì˜¬í•´, ë‚´ë…„
            r'\d{1,2}ì›”ë§|ì›”ì´ˆ',            # 3ì›”ë§, ì›”ì´ˆ
        ]
    
    def fetch_news_data(self, company_keyword: str, count: int = 20) -> List[Dict]:
        """External APIë¡œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            url = f"{self.base_url}/news/financial/{company_keyword}"
            params = {"count": count}
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            self.logger.info(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {company_keyword} - {len(items)}ê±´")
            return items
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - {company_keyword}: {e}")
            return []
    
    def fetch_disclosure_data(self, stock_code: str) -> List[Dict]:
        """External APIë¡œ ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ì¢…ëª©ì½”ë“œ -> ê¸°ì—…ì½”ë“œ ë§¤í•‘ (ì£¼ìš” ì¢…ëª©ë§Œ)
            stock_to_corp_mapping = {
                "005930": "00126380",  # ì‚¼ì„±ì „ì
                "000660": "00164779",  # SKí•˜ì´ë‹‰ìŠ¤
                "035720": "00401731",  # ì¹´ì¹´ì˜¤
                "051910": "00154449",  # LGí™”í•™
                "003550": "00164742"   # LG
            }
            
            corp_code = stock_to_corp_mapping.get(stock_code)
            if not corp_code:
                self.logger.warning(f"ê¸°ì—…ì½”ë“œ ë§¤í•‘ ì—†ìŒ: {stock_code}")
                return []
            
            url = f"{self.base_url}/disclosure/company/{corp_code}"
            params = {"days": 30, "count": 20}  # ìµœê·¼ 30ì¼ê°„ ê³µì‹œ
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("disclosures", [])
            
            self.logger.info(f"ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {stock_code} - {len(items)}ê±´")
            return items
            
        except Exception as e:
            self.logger.error(f"ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - {stock_code}: {e}")
            return []
    
    def extract_date_mentions(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì–¸ê¸‰ ì¶”ì¶œ"""
        date_mentions = []
        
        for pattern in self.date_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            date_mentions.extend(matches)
        
        return list(set(date_mentions))  # ì¤‘ë³µ ì œê±°
    
    def analyze_with_openai(self, news_data: List[Dict], disclosure_data: List[Dict]) -> Dict:
        """OpenAIë¥¼ í™œìš©í•œ ì´ë²¤íŠ¸ ë¶„ì„"""
        if not self.openai_available:
            return self._fallback_analysis(news_data, disclosure_data)
        
        try:
            # ë‰´ìŠ¤ì™€ ê³µì‹œ ì œëª©ë“¤ì„ ì¡°í•©
            all_texts = []
            
            # ë‰´ìŠ¤ ë°ì´í„° ì¶”ê°€
            for news in news_data[:10]:
                title = news.get("title", "").replace("<b>", "").replace("</b>", "")
                description = news.get("description", "")
                all_texts.append(f"[ë‰´ìŠ¤] {title} - {description}")
            
            # ê³µì‹œ ë°ì´í„° ì¶”ê°€
            for disclosure in disclosure_data[:10]:
                title = disclosure.get("report_nm", "")
                all_texts.append(f"[ê³µì‹œ] {title}")
            
            if not all_texts:
                return {"event_score": 0, "events": [], "analysis_summary": "ë¶„ì„í•  ë°ì´í„° ì—†ìŒ"}
            
            combined_text = "\n".join(all_texts)
            
            # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""
ë‹¤ìŒì€ í•œêµ­ ìƒì¥ê¸°ì—…ì˜ ìµœê·¼ ë‰´ìŠ¤ì™€ ê³µì‹œ ë‚´ìš©ì…ë‹ˆë‹¤. 

í…ìŠ¤íŠ¸:
{combined_text}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì²´í™”ëœ í˜¸ì¬ ì´ë²¤íŠ¸ë¥¼ ì°¾ì•„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ì‹œê¸°ê°€ ëª…ì‹œëœ í˜¸ì¬ì„± ì´ë²¤íŠ¸
   - ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ ì˜ˆì •
   - ì‹¤ì  ë°œí‘œ/IR í–‰ì‚¬ 
   - ê³„ì•½ ì²´ê²°/íŒŒíŠ¸ë„ˆì‹­
   - ìŠ¹ì¸/ì¸ì¦ ì·¨ë“
   - íˆ¬ì/M&A ê´€ë ¨
   
2. ë¶„ì„ ê¸°ì¤€:
   - êµ¬ì²´ì  ë‚ ì§œ ì–¸ê¸‰ + í˜¸ì¬ì„± ë‚´ìš© = ì ìˆ˜ ë¶€ì—¬
   - ë§‰ì—°í•œ í‘œí˜„("í–¥í›„", "ì–¸ì  ê°€")ì€ ì œì™¸
   - ì•…ì¬ë‚˜ ì¤‘ë¦½ì  ë‚´ìš©ì€ ì œì™¸

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "event_score": 0 ë˜ëŠ” 1 (êµ¬ì²´ì  í˜¸ì¬ ì´ë²¤íŠ¸ ìˆìœ¼ë©´ 1ì ),
    "events_count": ê°ì§€ëœ ì´ë²¤íŠ¸ ìˆ˜,
    "detected_events": [
        {{
            "event_type": "ì´ë²¤íŠ¸ ìœ í˜•",
            "description": "ì´ë²¤íŠ¸ ì„¤ëª…",
            "date_mention": "ë‚ ì§œ ì–¸ê¸‰ ë¶€ë¶„",
            "urgency_score": 0.0-1.0
        }}
    ],
    "analysis_summary": "ë¶„ì„ ìš”ì•½"
}}
            """
            
            # OpenAI API í˜¸ì¶œ
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì¦ì‹œ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë‚ ì§œê°€ ëª…ì‹œëœ í˜¸ì¬ ì´ë²¤íŠ¸ë¥¼ ì •í™•íˆ ì‹ë³„í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.1
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            import json
            try:
                result = json.loads(result_text)
                self.logger.info(f"âœ… OpenAI ì´ë²¤íŠ¸ ë¶„ì„ ì„±ê³µ: {result.get('analysis_summary', 'N/A')}")
                return result
            except json.JSONDecodeError:
                self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ: {result_text}")
                return self._fallback_analysis(news_data, disclosure_data)
                
        except Exception as e:
            self.logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_analysis(news_data, disclosure_data)
    
    def _fallback_analysis(self, news_data: List[Dict], disclosure_data: List[Dict]) -> Dict:
        """AI ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ì„"""
        detected_events = []
        
        # ë‰´ìŠ¤ ë¶„ì„
        for news in news_data:
            title = news.get("title", "").replace("<b>", "").replace("</b>", "")
            description = news.get("description", "")
            full_text = f"{title} {description}"
            
            # ë‚ ì§œ íŒ¨í„´ í™•ì¸
            date_mentions = self.extract_date_mentions(full_text)
            if not date_mentions:
                continue
            
            # í˜¸ì¬ì„± ì´ë²¤íŠ¸ í‚¤ì›Œë“œ í™•ì¸
            for event_type, keywords in self.positive_event_keywords.items():
                for keyword in keywords:
                    if keyword in full_text:
                        detected_events.append({
                            "event_type": event_type,
                            "description": title[:100],
                            "date_mention": ", ".join(date_mentions),
                            "source": "ë‰´ìŠ¤",
                            "urgency_score": 0.7
                        })
                        break
        
        # ê³µì‹œ ë¶„ì„
        for disclosure in disclosure_data:
            title = disclosure.get("report_nm", "")
            
            # ë‚ ì§œ íŒ¨í„´ í™•ì¸
            date_mentions = self.extract_date_mentions(title)
            if not date_mentions:
                continue
            
            # í˜¸ì¬ì„± ì´ë²¤íŠ¸ í‚¤ì›Œë“œ í™•ì¸
            for event_type, keywords in self.positive_event_keywords.items():
                for keyword in keywords:
                    if keyword in title:
                        detected_events.append({
                            "event_type": event_type,
                            "description": title,
                            "date_mention": ", ".join(date_mentions),
                            "source": "ê³µì‹œ",
                            "urgency_score": 0.8
                        })
                        break
        
        # ì ìˆ˜ ê³„ì‚°
        event_score = 1 if detected_events else 0
        
        return {
            "event_score": event_score,
            "events_count": len(detected_events),
            "detected_events": detected_events,
            "analysis_summary": f"í‚¤ì›Œë“œ ë¶„ì„: {len(detected_events)}ê°œ ì´ë²¤íŠ¸ ê°ì§€"
        }
    
    def analyze_imminent_events(self, stock_code: str, company_name: str = None) -> Optional[EventAnalysisResult]:
        """D001: êµ¬ì²´í™”ëœ ì´ë²¤íŠ¸/í˜¸ì¬ ì„ë°• ë¶„ì„"""
        
        search_keyword = company_name if company_name else stock_code
        
        self.logger.info(f"=== {search_keyword} ({stock_code}) D001 ì´ë²¤íŠ¸ ë¶„ì„ ì‹œì‘ ===")
        
        try:
            # 1. ë‰´ìŠ¤ ë° ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.fetch_news_data(search_keyword, count=20)
            disclosure_data = self.fetch_disclosure_data(stock_code)
            
            if not news_data and not disclosure_data:
                self.logger.warning(f"ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŒ: {search_keyword}")
                return None
            
            # 2. ì´ë²¤íŠ¸ ë¶„ì„ ìˆ˜í–‰
            ai_result = self.analyze_with_openai(news_data, disclosure_data)
            
            # 3. ê²°ê³¼ ìƒì„±
            result = EventAnalysisResult(
                company_name=search_keyword,
                stock_code=stock_code,
                total_sources=len(news_data) + len(disclosure_data),
                imminent_events_count=ai_result.get("events_count", 0),
                event_score=ai_result.get("event_score", 0),
                detected_events=ai_result.get("detected_events", []),
                analysis_summary=ai_result.get("analysis_summary", "")
            )
            
            self.logger.info(f"D001 ì´ë²¤íŠ¸ ë¶„ì„ ì™„ë£Œ - {search_keyword}: "
                            f"ì ìˆ˜ {result.event_score}, ì´ë²¤íŠ¸ {result.imminent_events_count}ê°œ")
            
            return result
            
        except Exception as e:
            self.logger.error(f"D001 ì´ë²¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨ - {stock_code}: {e}")
            return None

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    analyzer = EventAnalyzer()
    result = analyzer.analyze_imminent_events("005930", "ì‚¼ì„±ì „ì")
    
    if result:
        print(f"\nğŸ“… {result.company_name} ({result.stock_code}) D001 ì´ë²¤íŠ¸ ë¶„ì„ ê²°ê³¼")
        print(f"ë¶„ì„ ì†ŒìŠ¤: {result.total_sources}ê±´ (ë‰´ìŠ¤+ê³µì‹œ)")
        print(f"ì„ë°• ì´ë²¤íŠ¸: {result.imminent_events_count}ê°œ")
        print(f"D001 ì ìˆ˜: {result.event_score}ì ")
        
        if result.detected_events:
            print(f"\nê°ì§€ëœ ì´ë²¤íŠ¸:")
            for i, event in enumerate(result.detected_events, 1):
                print(f"{i}. [{event['event_type']}] {event['description']}")
                print(f"   ë‚ ì§œ: {event['date_mention']} | ì¶œì²˜: {event['source']}")
        
        print(f"\në¶„ì„ ìš”ì•½: {result.analysis_summary}")